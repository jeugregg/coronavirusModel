{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time Series for COVID: Publish for app\n",
    "\n",
    "This notebook use multistep time serie model  (predicting number of cases future next days).\n",
    "\n",
    "It converts Tensorflow model into TensorFlow Lite to be able to use it in a Lambda fonction on AWS.\n",
    "\n",
    "After that, the lite model is tested and publish on AWS\n",
    "\n",
    "Finally, the lambda function is tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model in TFlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT TO DO manually:**\n",
    "- **Update TRAIN_SPLIT in my_helpers.model module**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data useful lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# helper lib\n",
    "import shutil\n",
    "import os, stat\n",
    "import re\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "# read json from http\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "# read csv from http\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# model lib\n",
    "import tensorflow as tf\n",
    "\n",
    "# from project\n",
    "from my_helpers.model import prepare_to_lambda, retrieve_from_lambda\n",
    "from my_helpers.model import prepare_to_lambda_future\n",
    "from my_helpers.model import create_list_past_hist, predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SPLIT = 318\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_SAVE_DATA = \".\"\n",
    "PATH_DF_POS_FR = PATH_TO_SAVE_DATA + '/' + 'df_pos_fr.csv'\n",
    "PATH_DF_TEST_FR = PATH_TO_SAVE_DATA + '/' + 'df_test_fr.csv'\n",
    "PATH_JSON_METEO_FR = PATH_TO_SAVE_DATA + '/' + 'data_meteo_fr.json'\n",
    "PATH_DF_FEAT_FR = PATH_TO_SAVE_DATA + '/' + 'df_feat_fr.csv' \n",
    "PATH_GEO_DEP_FR = PATH_TO_SAVE_DATA + '/sources/geofrance/' + 'departments.csv'\n",
    "PATH_MDL_MULTI_STEP = PATH_TO_SAVE_DATA + '/' + \"mdl_multi_step_pos_fr_tcn\"\n",
    "PATH_MDL_MULTI_TFLITE = PATH_TO_SAVE_DATA + '/' + \\\n",
    "    'serverless/tensorflow_lite_on_aws_lambda'\n",
    "PATH_MDL_MULTI_TFLITE_FILE = PATH_MDL_MULTI_TFLITE + '/' + \\\n",
    "    \"converted_model.tflite\"\n",
    "PATH_SERVERLESS = PATH_MDL_MULTI_TFLITE + '/' + 'serverless.yml'\n",
    "\n",
    "date_format = \"%Y-%m-%d\"\n",
    "\n",
    "#NB_POS_DATE_MIN_DF_FEAT = 140734 # on 13/05/2020\n",
    "NB_POS_DATE_MIN_DF_FEAT = 140227 # on 12/05/2020\n",
    "\n",
    "URL_PREDICT = 'https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev/infer'\n",
    "\n",
    "# model \n",
    "PAST_HISTORY = 14 # days used to predict next values in future\n",
    "FUTURE_TARGET = 7 # nb predict days later\n",
    "STEP = 1\n",
    "\n",
    "# plot\n",
    "NB_DAY_PLOT = FUTURE_TARGET*9\n",
    "\n",
    "# train split\n",
    "from my_helpers.model import TRAIN_SPLIT\n",
    "print(f\"TRAIN_SPLIT = {TRAIN_SPLIT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file before update\n",
    "def clean_file(path_file_name):\n",
    "    '''\n",
    "    Clean file already traited : rename file with date\n",
    "    '''\n",
    "    try:\n",
    "        d = datetime.datetime.now()\n",
    "        str_date = '_' + d.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "       \n",
    "        res_re = re.search('\\.\\w+$', path_file_name)\n",
    "        \n",
    "        path_file_name_saved = \\\n",
    "            path_file_name[0:res_re.start()] + str_date + res_re.group(0)\n",
    "         \n",
    "        shutil.move(path_file_name, path_file_name_saved) \n",
    "        print('File {} moved!'.format(path_file_name_saved))\n",
    "    except:\n",
    "        print('File {} does not exist!'.format(path_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_min</th>\n",
       "      <th>date</th>\n",
       "      <th>T_max</th>\n",
       "      <th>H_min</th>\n",
       "      <th>H_max</th>\n",
       "      <th>extrap</th>\n",
       "      <th>pos</th>\n",
       "      <th>age_pos</th>\n",
       "      <th>test</th>\n",
       "      <th>age_test</th>\n",
       "      <th>day_num</th>\n",
       "      <th>nb_cases</th>\n",
       "      <th>sum_cases</th>\n",
       "      <th>Rt</th>\n",
       "      <th>rate_pos</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>284.926667</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>290.505000</td>\n",
       "      <td>64.661017</td>\n",
       "      <td>88.135593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>881</td>\n",
       "      <td>61.104427</td>\n",
       "      <td>39013</td>\n",
       "      <td>55.451567</td>\n",
       "      <td>3</td>\n",
       "      <td>141108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.258222</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>285.050000</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>290.963333</td>\n",
       "      <td>59.406780</td>\n",
       "      <td>84.847458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>981</td>\n",
       "      <td>60.403670</td>\n",
       "      <td>41975</td>\n",
       "      <td>54.832186</td>\n",
       "      <td>4</td>\n",
       "      <td>142089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.337105</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>285.308333</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>291.920000</td>\n",
       "      <td>57.372881</td>\n",
       "      <td>82.966102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1019</td>\n",
       "      <td>60.063788</td>\n",
       "      <td>47596</td>\n",
       "      <td>54.404446</td>\n",
       "      <td>5</td>\n",
       "      <td>143108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.140936</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-16</th>\n",
       "      <td>284.956667</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>293.500000</td>\n",
       "      <td>53.741379</td>\n",
       "      <td>86.534483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291</td>\n",
       "      <td>60.020619</td>\n",
       "      <td>16523</td>\n",
       "      <td>54.480058</td>\n",
       "      <td>6</td>\n",
       "      <td>143399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.761181</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-17</th>\n",
       "      <td>285.598333</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>294.446667</td>\n",
       "      <td>49.879310</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141</td>\n",
       "      <td>61.248227</td>\n",
       "      <td>6611</td>\n",
       "      <td>58.226895</td>\n",
       "      <td>0</td>\n",
       "      <td>143540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.132809</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-10</th>\n",
       "      <td>289.186667</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>297.723333</td>\n",
       "      <td>54.983333</td>\n",
       "      <td>86.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3787</td>\n",
       "      <td>38.742804</td>\n",
       "      <td>336583</td>\n",
       "      <td>38.754007</td>\n",
       "      <td>4</td>\n",
       "      <td>5669834</td>\n",
       "      <td>84142.0</td>\n",
       "      <td>0.543574</td>\n",
       "      <td>1.125131</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-11</th>\n",
       "      <td>289.486667</td>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>297.756667</td>\n",
       "      <td>55.766667</td>\n",
       "      <td>87.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3923</td>\n",
       "      <td>38.684935</td>\n",
       "      <td>376755</td>\n",
       "      <td>40.348685</td>\n",
       "      <td>5</td>\n",
       "      <td>5673757</td>\n",
       "      <td>77487.0</td>\n",
       "      <td>0.523578</td>\n",
       "      <td>1.041260</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-12</th>\n",
       "      <td>289.910000</td>\n",
       "      <td>2021-06-12</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>56.283333</td>\n",
       "      <td>87.433333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2170</td>\n",
       "      <td>38.973272</td>\n",
       "      <td>195235</td>\n",
       "      <td>45.751515</td>\n",
       "      <td>6</td>\n",
       "      <td>5675927</td>\n",
       "      <td>73344.0</td>\n",
       "      <td>0.504349</td>\n",
       "      <td>1.111481</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-13</th>\n",
       "      <td>289.546667</td>\n",
       "      <td>2021-06-13</td>\n",
       "      <td>299.260000</td>\n",
       "      <td>50.850000</td>\n",
       "      <td>87.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>491</td>\n",
       "      <td>41.580448</td>\n",
       "      <td>45252</td>\n",
       "      <td>49.353377</td>\n",
       "      <td>0</td>\n",
       "      <td>5676418</td>\n",
       "      <td>72363.0</td>\n",
       "      <td>0.500477</td>\n",
       "      <td>1.085035</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-14</th>\n",
       "      <td>289.731667</td>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>299.831667</td>\n",
       "      <td>49.766667</td>\n",
       "      <td>83.683333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3867</td>\n",
       "      <td>39.822084</td>\n",
       "      <td>336022</td>\n",
       "      <td>43.142193</td>\n",
       "      <td>1</td>\n",
       "      <td>5680285</td>\n",
       "      <td>64496.0</td>\n",
       "      <td>0.472149</td>\n",
       "      <td>1.150818</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 T_min        date       T_max      H_min      H_max  extrap  \\\n",
       "date                                                                           \n",
       "2020-05-13  284.926667  2020-05-13  290.505000  64.661017  88.135593     0.0   \n",
       "2020-05-14  285.050000  2020-05-14  290.963333  59.406780  84.847458     0.0   \n",
       "2020-05-15  285.308333  2020-05-15  291.920000  57.372881  82.966102     0.0   \n",
       "2020-05-16  284.956667  2020-05-16  293.500000  53.741379  86.534483     0.0   \n",
       "2020-05-17  285.598333  2020-05-17  294.446667  49.879310  85.500000     0.0   \n",
       "...                ...         ...         ...        ...        ...     ...   \n",
       "2021-06-10  289.186667  2021-06-10  297.723333  54.983333  86.416667     0.0   \n",
       "2021-06-11  289.486667  2021-06-11  297.756667  55.766667  87.200000     0.0   \n",
       "2021-06-12  289.910000  2021-06-12  298.000000  56.283333  87.433333     0.0   \n",
       "2021-06-13  289.546667  2021-06-13  299.260000  50.850000  87.416667     0.0   \n",
       "2021-06-14  289.731667  2021-06-14  299.831667  49.766667  83.683333     0.0   \n",
       "\n",
       "             pos    age_pos    test   age_test  day_num  nb_cases  sum_cases  \\\n",
       "date                                                                           \n",
       "2020-05-13   881  61.104427   39013  55.451567        3    141108        NaN   \n",
       "2020-05-14   981  60.403670   41975  54.832186        4    142089        NaN   \n",
       "2020-05-15  1019  60.063788   47596  54.404446        5    143108        NaN   \n",
       "2020-05-16   291  60.020619   16523  54.480058        6    143399        NaN   \n",
       "2020-05-17   141  61.248227    6611  58.226895        0    143540        NaN   \n",
       "...          ...        ...     ...        ...      ...       ...        ...   \n",
       "2021-06-10  3787  38.742804  336583  38.754007        4   5669834    84142.0   \n",
       "2021-06-11  3923  38.684935  376755  40.348685        5   5673757    77487.0   \n",
       "2021-06-12  2170  38.973272  195235  45.751515        6   5675927    73344.0   \n",
       "2021-06-13   491  41.580448   45252  49.353377        0   5676418    72363.0   \n",
       "2021-06-14  3867  39.822084  336022  43.142193        1   5680285    64496.0   \n",
       "\n",
       "                  Rt  rate_pos  train  \n",
       "date                                   \n",
       "2020-05-13       NaN  2.258222   True  \n",
       "2020-05-14       NaN  2.337105   True  \n",
       "2020-05-15       NaN  2.140936   True  \n",
       "2020-05-16       NaN  1.761181   True  \n",
       "2020-05-17       NaN  2.132809   True  \n",
       "...              ...       ...    ...  \n",
       "2021-06-10  0.543574  1.125131  False  \n",
       "2021-06-11  0.523578  1.041260  False  \n",
       "2021-06-12  0.504349  1.111481  False  \n",
       "2021-06-13  0.500477  1.085035  False  \n",
       "2021-06-14  0.472149  1.150818  False  \n",
       "\n",
       "[398 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_fr = pd.read_csv(PATH_DF_FEAT_FR)\n",
    "df_feat_fr.index = df_feat_fr[\"date\"]\n",
    "df_feat_fr[\"train\"] = [True if I <= TRAIN_SPLIT else False \\\n",
    "                       for I in range(df_feat_fr.shape[0])]\n",
    "df_feat_fr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_min</th>\n",
       "      <th>T_max</th>\n",
       "      <th>H_min</th>\n",
       "      <th>H_max</th>\n",
       "      <th>pos</th>\n",
       "      <th>test</th>\n",
       "      <th>day_num</th>\n",
       "      <th>age_pos</th>\n",
       "      <th>age_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>284.926667</td>\n",
       "      <td>290.505000</td>\n",
       "      <td>64.661017</td>\n",
       "      <td>88.135593</td>\n",
       "      <td>881</td>\n",
       "      <td>39013</td>\n",
       "      <td>3</td>\n",
       "      <td>61.104427</td>\n",
       "      <td>55.451567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>285.050000</td>\n",
       "      <td>290.963333</td>\n",
       "      <td>59.406780</td>\n",
       "      <td>84.847458</td>\n",
       "      <td>981</td>\n",
       "      <td>41975</td>\n",
       "      <td>4</td>\n",
       "      <td>60.403670</td>\n",
       "      <td>54.832186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>285.308333</td>\n",
       "      <td>291.920000</td>\n",
       "      <td>57.372881</td>\n",
       "      <td>82.966102</td>\n",
       "      <td>1019</td>\n",
       "      <td>47596</td>\n",
       "      <td>5</td>\n",
       "      <td>60.063788</td>\n",
       "      <td>54.404446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-16</th>\n",
       "      <td>284.956667</td>\n",
       "      <td>293.500000</td>\n",
       "      <td>53.741379</td>\n",
       "      <td>86.534483</td>\n",
       "      <td>291</td>\n",
       "      <td>16523</td>\n",
       "      <td>6</td>\n",
       "      <td>60.020619</td>\n",
       "      <td>54.480058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-17</th>\n",
       "      <td>285.598333</td>\n",
       "      <td>294.446667</td>\n",
       "      <td>49.879310</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>141</td>\n",
       "      <td>6611</td>\n",
       "      <td>0</td>\n",
       "      <td>61.248227</td>\n",
       "      <td>58.226895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-10</th>\n",
       "      <td>289.186667</td>\n",
       "      <td>297.723333</td>\n",
       "      <td>54.983333</td>\n",
       "      <td>86.416667</td>\n",
       "      <td>3787</td>\n",
       "      <td>336583</td>\n",
       "      <td>4</td>\n",
       "      <td>38.742804</td>\n",
       "      <td>38.754007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-11</th>\n",
       "      <td>289.486667</td>\n",
       "      <td>297.756667</td>\n",
       "      <td>55.766667</td>\n",
       "      <td>87.200000</td>\n",
       "      <td>3923</td>\n",
       "      <td>376755</td>\n",
       "      <td>5</td>\n",
       "      <td>38.684935</td>\n",
       "      <td>40.348685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-12</th>\n",
       "      <td>289.910000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>56.283333</td>\n",
       "      <td>87.433333</td>\n",
       "      <td>2170</td>\n",
       "      <td>195235</td>\n",
       "      <td>6</td>\n",
       "      <td>38.973272</td>\n",
       "      <td>45.751515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-13</th>\n",
       "      <td>289.546667</td>\n",
       "      <td>299.260000</td>\n",
       "      <td>50.850000</td>\n",
       "      <td>87.416667</td>\n",
       "      <td>491</td>\n",
       "      <td>45252</td>\n",
       "      <td>0</td>\n",
       "      <td>41.580448</td>\n",
       "      <td>49.353377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-14</th>\n",
       "      <td>289.731667</td>\n",
       "      <td>299.831667</td>\n",
       "      <td>49.766667</td>\n",
       "      <td>83.683333</td>\n",
       "      <td>3867</td>\n",
       "      <td>336022</td>\n",
       "      <td>1</td>\n",
       "      <td>39.822084</td>\n",
       "      <td>43.142193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 T_min       T_max      H_min      H_max   pos    test  \\\n",
       "date                                                                     \n",
       "2020-05-13  284.926667  290.505000  64.661017  88.135593   881   39013   \n",
       "2020-05-14  285.050000  290.963333  59.406780  84.847458   981   41975   \n",
       "2020-05-15  285.308333  291.920000  57.372881  82.966102  1019   47596   \n",
       "2020-05-16  284.956667  293.500000  53.741379  86.534483   291   16523   \n",
       "2020-05-17  285.598333  294.446667  49.879310  85.500000   141    6611   \n",
       "...                ...         ...        ...        ...   ...     ...   \n",
       "2021-06-10  289.186667  297.723333  54.983333  86.416667  3787  336583   \n",
       "2021-06-11  289.486667  297.756667  55.766667  87.200000  3923  376755   \n",
       "2021-06-12  289.910000  298.000000  56.283333  87.433333  2170  195235   \n",
       "2021-06-13  289.546667  299.260000  50.850000  87.416667   491   45252   \n",
       "2021-06-14  289.731667  299.831667  49.766667  83.683333  3867  336022   \n",
       "\n",
       "            day_num    age_pos   age_test  \n",
       "date                                       \n",
       "2020-05-13        3  61.104427  55.451567  \n",
       "2020-05-14        4  60.403670  54.832186  \n",
       "2020-05-15        5  60.063788  54.404446  \n",
       "2020-05-16        6  60.020619  54.480058  \n",
       "2020-05-17        0  61.248227  58.226895  \n",
       "...             ...        ...        ...  \n",
       "2021-06-10        4  38.742804  38.754007  \n",
       "2021-06-11        5  38.684935  40.348685  \n",
       "2021-06-12        6  38.973272  45.751515  \n",
       "2021-06-13        0  41.580448  49.353377  \n",
       "2021-06-14        1  39.822084  43.142193  \n",
       "\n",
       "[398 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_feat_fr.copy().filter(items=['T_min', 'T_max', 'H_min',\n",
    "                                           'H_max', 'pos', 'test', 'day_num',\n",
    "                                          'age_pos', 'age_test'])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = features.values\n",
    "data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\n",
    "data_std = dataset[:TRAIN_SPLIT].std(axis=0)\n",
    "dataset = (dataset-data_mean)/data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAST_HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/coronavirusModel/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:1061: UserWarning: tcn.tcn is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  , UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 79.3 ms, total: 1.27 s\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reload best model\n",
    "multi_step_model = tf.keras.models.load_model(PATH_MDL_MULTI_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 14, 9)]           0         \n",
      "_________________________________________________________________\n",
      "tcn (TCN)                    (None, 64)                43136     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 43,591\n",
      "Trainable params: 43,591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "multi_step_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_step_model.inputs[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 125). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./keras_tcn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./keras_tcn/assets\n"
     ]
    }
   ],
   "source": [
    "run_model = tf.function(lambda x: multi_step_model(x))\n",
    "# This is important, let's fix the input size.\n",
    "INPUT_SIZE = dataset.shape[1]\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([1, PAST_HISTORY, INPUT_SIZE],\n",
    "                  multi_step_model.inputs[0].dtype))\n",
    "\n",
    "# model directory.\n",
    "MODEL_DIR = PATH_TO_SAVE_DATA + \"/\" + \"keras_tcn\"\n",
    "multi_step_model.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "\n",
    "'''converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "converter.allow_custom_ops=True'''\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./serverless/tensorflow_lite_on_aws_lambda/converted_model_20210622_08_25_36.tflite moved!\n"
     ]
    }
   ],
   "source": [
    "clean_file(PATH_MDL_MULTI_TFLITE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./serverless/tensorflow_lite_on_aws_lambda/converted_model.tflite'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_MDL_MULTI_TFLITE_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188892"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(PATH_MDL_MULTI_TFLITE_FILE, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test converted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with TF model (not-converted one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[321 - 335]\n",
      "[328 - 342]\n",
      "[335 - 349]\n",
      "[342 - 356]\n",
      "[349 - 363]\n",
      "[356 - 370]\n",
      "[363 - 377]\n",
      "[370 - 384]\n",
      "[377 - 391]\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29666.922  , 26996.371  , 28165.648  , 31385.72   , 19210.123  ,\n",
       "         9948.079  , 34728.113  , 28436.117  , 27424.426  , 24031.824  ,\n",
       "        26893.992  , 19191.252  , 10096.86   , 30991.406  , 24586.94   ,\n",
       "        23193.324  , 20728.414  , 24644.582  , 21748.125  , 10572.421  ,\n",
       "        27509.447  , 20609.107  , 21189.688  , 17618.365  , 18332.193  ,\n",
       "        17891.316  , 13277.501  , 29824.629  , 17055.047  , 14979.952  ,\n",
       "        13569.202  , 17585.182  , 10375.552  ,  6525.003  , 25564.52   ,\n",
       "        17005.709  , 14123.661  ,  9407.52   , 15494.065  , 11914.357  ,\n",
       "         9765.455  , 22527.896  , 13434.8    , 14472.842  , 12226.064  ,\n",
       "        12567.557  , 10380.274  ,  8974.154  ,  9123.854  , 10548.352  ,\n",
       "        11262.53   ,  9826.993  ,  9020.069  ,  4786.5684 ,  1300.3066 ,\n",
       "        15870.695  , 10750.324  , 10246.054  ,  4879.8633 ,  7482.1123 ,\n",
       "         2868.712  ,   512.15234, 13497.69   ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSORFLOW MODEL :\n",
    "# prepare list of past histories\n",
    "list_x = create_list_past_hist(dataset)\n",
    "# predict\n",
    "y_multi_pred = predict_list(list_x, multi_step_model)\n",
    "# convert in positive cases\n",
    "y_pos_pred = (y_multi_pred * data_std[4]) + data_mean[4] \n",
    "y_pos_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data : very last days\n",
    "x_for_future = np.array([dataset[-PAST_HISTORY:,:]]) \n",
    "# predict next days\n",
    "y_future_pred = multi_step_model.predict(x_for_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with TFlite & Compare "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# CONVERTED LITE MODEL\n",
    "# load \n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "\n",
    "# Run the model with TensorFlow Lite\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# check if same results \n",
    "for x_multi in list_x:\n",
    "    # predict with tensorflow model\n",
    "    expected = multi_step_model.predict(x_multi)\n",
    "    # predict with TFlite model\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], \n",
    "                           x_multi.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "    # Assert if the result of TFLite model is consistent with the TF model.\n",
    "    np.testing.assert_almost_equal(expected, result, decimal=3)\n",
    "    print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "    # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "    # the states.\n",
    "    # Clean up internal states.\n",
    "    interpreter.reset_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Tlite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=PATH_MDL_MULTI_TFLITE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./serverless/tensorflow_lite_on_aws_lambda/converted_model.tflite'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_MDL_MULTI_TFLITE_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict reloaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Run the model with TensorFlow Lite\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# check if same results \n",
    "for x_multi in list_x:\n",
    "    \n",
    "    expected = multi_step_model.predict(x_multi)\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0][\"index\"], \n",
    "                           x_multi.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "    # Assert if the result of TFLite model is consistent with the TF model.\n",
    "    np.testing.assert_almost_equal(expected, result, decimal=3)\n",
    "    print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "    # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "    # the states.\n",
    "    # Clean up internal states.\n",
    "    interpreter.reset_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14, 9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update API lambda AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API lambda simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[321 - 335]\n",
      "[328 - 342]\n",
      "[335 - 349]\n",
      "[342 - 356]\n",
      "[349 - 363]\n",
      "[356 - 370]\n",
      "[363 - 377]\n",
      "[370 - 384]\n",
      "[377 - 391]\n"
     ]
    }
   ],
   "source": [
    "json_list_list_x = prepare_to_lambda(dataset)\n",
    "# simulate input to lambda (double dumps ? why ? i don't know yet)\n",
    "json_list_list_x = json.dumps(json_list_list_x)\n",
    "# simulate lambda\n",
    "\n",
    "event = {\"body\": json_list_list_x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT : nb. arrays : 9 / arrays shape: (1, 14, 9)\n",
      "OUTPUT : nb. arrays : 9 / arrays shape in list: (1, 7)\n"
     ]
    }
   ],
   "source": [
    "# lambda code (file ./serverless/tensorflow-lite-on-aws-lambda/handler.py)\n",
    "from serverless.tensorflow_lite_on_aws_lambda.handler import predict\n",
    "context = None\n",
    "response = predict(event, context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve from lambda in App code\n",
    "# input : response\n",
    "y_multi_pred_out = retrieve_from_lambda(response)      \n",
    "y_multi_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1958351 ,  1.0042262 ,  1.0881205 ,  1.3191568 ,  0.4455724 ,\n",
       "        -0.218968  ,  1.5589695 ,  1.1075264 ,  1.0349387 ,  0.7915236 ,\n",
       "         0.99688077,  0.4442185 , -0.20829311,  1.2908653 ,  0.83135253,\n",
       "         0.7313622 ,  0.5545079 ,  0.8354882 ,  0.62767106, -0.1741722 ,\n",
       "         1.0410389 ,  0.54594785,  0.5876038 ,  0.3313658 ,  0.38258207,\n",
       "         0.3509497 ,  0.01991402,  1.2071503 ,  0.29094827,  0.14206283,\n",
       "         0.0408432 ,  0.32898492, -0.18829736, -0.46456954,  0.9014928 ,\n",
       "         0.28740835,  0.08062498, -0.25775248,  0.1789498 , -0.0778899 ,\n",
       "        -0.23207107,  0.68361866,  0.0312    ,  0.10567823, -0.05552532,\n",
       "        -0.03102365, -0.18795848, -0.28884587, -0.27810514, -0.1758992 ,\n",
       "        -0.12465773, -0.22765577, -0.28555155, -0.58930016, -0.83943516,\n",
       "         0.2059726 , -0.16140789, -0.19758867, -0.5826063 , -0.3958981 ,\n",
       "        -0.726904  , -0.8959843 ,  0.03571232]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.19583523,  1.00422609,  1.08812034,  1.319157  ,  0.44557238,\n",
       "        -0.21896777,  1.55896986,  1.1075263 ,  1.03493869,  0.79152352,\n",
       "         0.99688053,  0.44421849, -0.2082932 ,  1.2908653 ,  0.83135241,\n",
       "         0.73136199,  0.55450785,  0.8354882 ,  0.62767106, -0.17417222,\n",
       "         1.04103875,  0.54594767,  0.58760369,  0.33136582,  0.38258219,\n",
       "         0.3509497 ,  0.01991422,  1.20715046,  0.29094827,  0.14206269,\n",
       "         0.0408432 ,  0.3289848 , -0.18829742, -0.46456942,  0.90149271,\n",
       "         0.28740838,  0.08062491, -0.25775248,  0.17894992, -0.07788995,\n",
       "        -0.2320711 ,  0.68361866,  0.03119985,  0.10567832, -0.05552541,\n",
       "        -0.03102371, -0.18795848, -0.28884581, -0.27810514, -0.1758991 ,\n",
       "        -0.1246579 , -0.22765586, -0.28555155, -0.58930022, -0.83943516,\n",
       "         0.20597251, -0.16140766, -0.19758859, -0.58260596, -0.39589795,\n",
       "        -0.7269038 , -0.89598417,  0.03571235]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_multi_pred, y_multi_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT : nb. arrays : 1 / arrays shape: (1, 14, 9)\n",
      "OUTPUT : nb. arrays : 1 / arrays shape in list: (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data to lambda (future)\n",
    "json_list_list_x = prepare_to_lambda_future(dataset)\n",
    "\n",
    "# simulate lambda\n",
    "json_list_list_x = json.dumps(json_list_list_x) # dumps again : I dont know why\n",
    "event = {\"body\": json_list_list_x}\n",
    "context = None\n",
    "response = predict(event, context)\n",
    "y_future_pred_out = retrieve_from_lambda(response)      \n",
    "y_future_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5843907 , -0.3629649 , -0.48085707, -0.53998703, -0.89822507,\n",
       "        -0.9459039 , -0.35014218]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5843906 , -0.36296496, -0.4808569 , -0.5399871 , -0.8982251 ,\n",
       "        -0.9459039 , -0.35014212]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_future_pred, y_future_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update AWS Lambda with new model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part does:\n",
    "- Go to : ./serverless//tensorflow-lite-on-aws-lambda\n",
    "    \n",
    "- Execute : sls deploy -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#!/bin/bash\\nexport PATH=\"/usr/local/bin:$PATH\"\\ncd ./serverless/tensorflow_lite_on_aws_lambda\\nserverless deploy -v'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_exe = '#!/bin/bash\\n' + \\\n",
    "    'export PATH=\"/usr/local/bin:$PATH\"\\n' + \\\n",
    "    f'cd {PATH_MDL_MULTI_TFLITE}\\n' + \\\n",
    "    'serverless deploy -v'\n",
    "str_exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('deploy_serverless.sh', \"w\").write(str_exe)\n",
    "os.chmod('deploy_serverless.sh', stat.S_IRWXU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "export PATH=\"/usr/local/bin:$PATH\"\r\n",
      "cd ./serverless/tensorflow_lite_on_aws_lambda\r\n",
      "serverless deploy -v"
     ]
    }
   ],
   "source": [
    "!cat ./deploy_serverless.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serverless: \u001b[93mDeprecation warning: Resolution of lambda version hashes was improved with better algorithm, which will be used in next major release.\u001b[39m\n",
      "\u001b[93m            Switch to it now by setting \"provider.lambdaHashingVersion\" to \"20201221\"\u001b[39m\n",
      "            \u001b[93mMore Info: https://www.serverless.com/framework/docs/deprecations/#LAMBDA_HASHING_VERSION_V2\u001b[39m\n",
      "Serverless: \u001b[33mGenerated requirements from /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow_lite_on_aws_lambda/requirements.txt in /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow_lite_on_aws_lambda/.serverless/requirements.txt...\u001b[39m\n",
      "Serverless: \u001b[33mUsing static cache of requirements found at /Users/gregory/Library/Caches/serverless-python-requirements/eddadf68f9f2c21cf494701082a5393692d7b3c4711137913b3ed1b03bec68cf_slspyc ...\u001b[39m\n",
      "Serverless: \u001b[33mPackaging service...\u001b[39m\n",
      "Serverless: \u001b[33mExcluding development dependencies...\u001b[39m\n",
      "Serverless: \u001b[33mInjecting required Python packages to package...\u001b[39m\n",
      "Serverless: \u001b[33mUploading CloudFormation file to S3...\u001b[39m\n",
      "Serverless: \u001b[33mUploading artifacts...\u001b[39m\n",
      "Serverless: \u001b[33mUploading service tensorflow-lite-on-aws-lambda.zip file to S3 (19.83 MB)...\u001b[39m\n",
      "Serverless: \u001b[33mValidating template...\u001b[39m\n",
      "Serverless: \u001b[33mUpdating Stack...\u001b[39m\n",
      "Serverless: \u001b[33mChecking Stack update progress...\u001b[39m\n",
      "CloudFormation - \u001b[33mUPDATE_IN_PROGRESS\u001b[39m - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-dev\n",
      "CloudFormation - \u001b[33mUPDATE_IN_PROGRESS\u001b[39m - AWS::Lambda::Function - PredictLambdaFunction\n",
      "CloudFormation - \u001b[32mUPDATE_COMPLETE\u001b[39m - AWS::Lambda::Function - PredictLambdaFunction\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::Lambda::Version - PredictLambdaVersiongw7wsN1Vlk08dxak77orTXa73QyzBVgkh0wGZirrkEQ\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::Lambda::Version - PredictLambdaVersiongw7wsN1Vlk08dxak77orTXa73QyzBVgkh0wGZirrkEQ\n",
      "CloudFormation - \u001b[32mCREATE_COMPLETE\u001b[39m - AWS::Lambda::Version - PredictLambdaVersiongw7wsN1Vlk08dxak77orTXa73QyzBVgkh0wGZirrkEQ\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1624343868204\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1624343868204\n",
      "CloudFormation - \u001b[32mCREATE_COMPLETE\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1624343868204\n",
      "CloudFormation - \u001b[33mUPDATE_COMPLETE_CLEANUP_IN_PROGRESS\u001b[39m - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-dev\n",
      "CloudFormation - DELETE_SKIPPED - AWS::Lambda::Version - PredictLambdaVersionqATP6fkvS5kX0R3OOiLK7fh9v2wl0glNj1Po0wCkQ8E\n",
      "CloudFormation - \u001b[33mDELETE_IN_PROGRESS\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1620919003014\n",
      "CloudFormation - \u001b[32mDELETE_COMPLETE\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1620919003014\n",
      "CloudFormation - \u001b[32mUPDATE_COMPLETE\u001b[39m - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-dev\n",
      "Serverless: \u001b[33mStack update finished...\u001b[39m\n",
      "\u001b[33m\u001b[4mService Information\u001b[24m\u001b[39m\n",
      "\u001b[33mservice:\u001b[39m tensorflow-lite-on-aws-lambda\n",
      "\u001b[33mstage:\u001b[39m dev\n",
      "\u001b[33mregion:\u001b[39m us-east-2\n",
      "\u001b[33mstack:\u001b[39m tensorflow-lite-on-aws-lambda-dev\n",
      "\u001b[33mresources:\u001b[39m 11\n",
      "\u001b[33mapi keys:\u001b[39m\n",
      "  None\n",
      "\u001b[33mendpoints:\u001b[39m\n",
      "  POST - https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev/infer\n",
      "\u001b[33mfunctions:\u001b[39m\n",
      "  predict: tensorflow-lite-on-aws-lambda-dev-predict\n",
      "\u001b[33mlayers:\u001b[39m\n",
      "  None\n",
      "\u001b[33m\u001b[4m\u001b[24m\u001b[39m\n",
      "\u001b[33m\u001b[4mStack Outputs\u001b[24m\u001b[39m\n",
      "\u001b[33m\u001b[4m\u001b[24m\u001b[39m\u001b[33mPredictLambdaFunctionQualifiedArn\u001b[39m: arn:aws:lambda:us-east-2:324466407431:function:tensorflow-lite-on-aws-lambda-dev-predict:15\n",
      "\u001b[33mServiceEndpoint\u001b[39m: https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev\n",
      "\u001b[33mServerlessDeploymentBucketName\u001b[39m: tensorflow-lite-on-aws-l-serverlessdeploymentbuck-1vuz80v36l59q\n",
      "\n",
      "Serverless: \u001b[33mRemoving old service artifacts from S3...\u001b[39m\n",
      "\n",
      "********************************************************************************\n",
      "Serverless: \u001b[33mUpdate available. Run \"npm install -g serverless@^2.48.0\" to update\u001b[39m\n",
      "\u001b[33m            You may turn on automatic updates via \"serverless config --autoupdate\"\u001b[39m\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./deploy_serverless.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API AWS real Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[321 - 335]\n",
      "[328 - 342]\n",
      "[335 - 349]\n",
      "[342 - 356]\n",
      "[349 - 363]\n",
      "[356 - 370]\n",
      "[363 - 377]\n",
      "[370 - 384]\n",
      "[377 - 391]\n",
      "status code :  200\n",
      "[[[1.1958352327346802, 1.0042260885238647, 1.0881203413009644, 1.3191570043563843, 0.44557255506515503, -0.21896782517433167, 1.5589698553085327]], [[1.1075263023376465, 1.0349386930465698, 0.7915234565734863, 0.9968806505203247, 0.4442184567451477, -0.20829322934150696, 1.2908653020858765]], [[0.8313524127006531, 0.7313621044158936, 0.5545077919960022, 0.8354882001876831, 0.6276711225509644, -0.17417222261428833, 1.0410387516021729]], [[0.5459477305412292, 0.5876038074493408, 0.3313658833503723, 0.3825821876525879, 0.3509496748447418, 0.019914261996746063, 1.2071503400802612]], [[0.2909482717514038, 0.14206287264823914, 0.04084325581789017, 0.3289848566055298, -0.18829742074012756, -0.4645695388317108, 0.9014928936958313]], [[0.28740838170051575, 0.0806250274181366, -0.2577524781227112, 0.17894989252090454, -0.07788991928100586, -0.23207107186317444, 0.6836186647415161]], [[0.031199822202324867, 0.10567834973335266, -0.05552538484334946, -0.03102371096611023, -0.1879585087299347, -0.2888459265232086, -0.27810508012771606]], [[-0.17589910328388214, -0.12465789914131165, -0.227655827999115, -0.2855515480041504, -0.5893001556396484, -0.8394351005554199, 0.20597253739833832]], [[-0.1614077240228653, -0.19758859276771545, -0.5826059579849243, -0.39589792490005493, -0.7269038558006287, -0.8959840536117554, 0.035712435841560364]]]\n"
     ]
    }
   ],
   "source": [
    "# prepare input\n",
    "json_list_list_x = prepare_to_lambda(dataset)\n",
    "# REQUEST\n",
    "resp = requests.post(URL_PREDICT, json=json_list_list_x)\n",
    "print(\"status code : \", resp.status_code) \n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23817"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_list_list_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1.1958352327346802,\n",
       "   1.0042260885238647,\n",
       "   1.0881203413009644,\n",
       "   1.3191570043563843,\n",
       "   0.44557255506515503,\n",
       "   -0.21896782517433167,\n",
       "   1.5589698553085327]],\n",
       " [[1.1075263023376465,\n",
       "   1.0349386930465698,\n",
       "   0.7915234565734863,\n",
       "   0.9968806505203247,\n",
       "   0.4442184567451477,\n",
       "   -0.20829322934150696,\n",
       "   1.2908653020858765]],\n",
       " [[0.8313524127006531,\n",
       "   0.7313621044158936,\n",
       "   0.5545077919960022,\n",
       "   0.8354882001876831,\n",
       "   0.6276711225509644,\n",
       "   -0.17417222261428833,\n",
       "   1.0410387516021729]],\n",
       " [[0.5459477305412292,\n",
       "   0.5876038074493408,\n",
       "   0.3313658833503723,\n",
       "   0.3825821876525879,\n",
       "   0.3509496748447418,\n",
       "   0.019914261996746063,\n",
       "   1.2071503400802612]],\n",
       " [[0.2909482717514038,\n",
       "   0.14206287264823914,\n",
       "   0.04084325581789017,\n",
       "   0.3289848566055298,\n",
       "   -0.18829742074012756,\n",
       "   -0.4645695388317108,\n",
       "   0.9014928936958313]],\n",
       " [[0.28740838170051575,\n",
       "   0.0806250274181366,\n",
       "   -0.2577524781227112,\n",
       "   0.17894989252090454,\n",
       "   -0.07788991928100586,\n",
       "   -0.23207107186317444,\n",
       "   0.6836186647415161]],\n",
       " [[0.031199822202324867,\n",
       "   0.10567834973335266,\n",
       "   -0.05552538484334946,\n",
       "   -0.03102371096611023,\n",
       "   -0.1879585087299347,\n",
       "   -0.2888459265232086,\n",
       "   -0.27810508012771606]],\n",
       " [[-0.17589910328388214,\n",
       "   -0.12465789914131165,\n",
       "   -0.227655827999115,\n",
       "   -0.2855515480041504,\n",
       "   -0.5893001556396484,\n",
       "   -0.8394351005554199,\n",
       "   0.20597253739833832]],\n",
       " [[-0.1614077240228653,\n",
       "   -0.19758859276771545,\n",
       "   -0.5826059579849243,\n",
       "   -0.39589792490005493,\n",
       "   -0.7269038558006287,\n",
       "   -0.8959840536117554,\n",
       "   0.035712435841560364]]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out = retrieve_from_lambda(resp)      \n",
    "y_multi_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.19583523,  1.00422609,  1.08812034,  1.319157  ,  0.44557256,\n",
       "        -0.21896783,  1.55896986,  1.1075263 ,  1.03493869,  0.79152346,\n",
       "         0.99688065,  0.44421846, -0.20829323,  1.2908653 ,  0.83135241,\n",
       "         0.7313621 ,  0.55450779,  0.8354882 ,  0.62767112, -0.17417222,\n",
       "         1.04103875,  0.54594773,  0.58760381,  0.33136588,  0.38258219,\n",
       "         0.35094967,  0.01991426,  1.20715034,  0.29094827,  0.14206287,\n",
       "         0.04084326,  0.32898486, -0.18829742, -0.46456954,  0.90149289,\n",
       "         0.28740838,  0.08062503, -0.25775248,  0.17894989, -0.07788992,\n",
       "        -0.23207107,  0.68361866,  0.03119982,  0.10567835, -0.05552538,\n",
       "        -0.03102371, -0.18795851, -0.28884593, -0.27810508, -0.1758991 ,\n",
       "        -0.1246579 , -0.22765583, -0.28555155, -0.58930016, -0.8394351 ,\n",
       "         0.20597254, -0.16140772, -0.19758859, -0.58260596, -0.39589792,\n",
       "        -0.72690386, -0.89598405,  0.03571244]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1958351 ,  1.0042262 ,  1.0881205 ,  1.3191568 ,  0.4455724 ,\n",
       "        -0.218968  ,  1.5589695 ,  1.1075264 ,  1.0349387 ,  0.7915236 ,\n",
       "         0.99688077,  0.4442185 , -0.20829311,  1.2908653 ,  0.83135253,\n",
       "         0.7313622 ,  0.5545079 ,  0.8354882 ,  0.62767106, -0.1741722 ,\n",
       "         1.0410389 ,  0.54594785,  0.5876038 ,  0.3313658 ,  0.38258207,\n",
       "         0.3509497 ,  0.01991402,  1.2071503 ,  0.29094827,  0.14206283,\n",
       "         0.0408432 ,  0.32898492, -0.18829736, -0.46456954,  0.9014928 ,\n",
       "         0.28740835,  0.08062498, -0.25775248,  0.1789498 , -0.0778899 ,\n",
       "        -0.23207107,  0.68361866,  0.0312    ,  0.10567823, -0.05552532,\n",
       "        -0.03102365, -0.18795848, -0.28884587, -0.27810514, -0.1758992 ,\n",
       "        -0.12465773, -0.22765577, -0.28555155, -0.58930016, -0.83943516,\n",
       "         0.2059726 , -0.16140789, -0.19758867, -0.5826063 , -0.3958981 ,\n",
       "        -0.726904  , -0.8959843 ,  0.03571232]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_multi_pred, y_multi_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### future days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status code :  200\n",
      "[[[-0.5843907594680786, -0.36296501755714417, -0.4808571934700012, -0.5399870276451111, -0.8982250690460205, -0.9459038972854614, -0.350142240524292]]]\n"
     ]
    }
   ],
   "source": [
    "# prepare input\n",
    "json_list_list_x = prepare_to_lambda_future(dataset)\n",
    "# REQUEST URL_PREDICT = 'https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev/infer' \n",
    "resp = requests.post(URL_PREDICT, json=json_list_list_x)\n",
    "print(\"status code : \", resp.status_code) \n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.58439076, -0.36296502, -0.48085719, -0.53998703, -0.89822507,\n",
       "        -0.9459039 , -0.35014224]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred_out = retrieve_from_lambda(resp)      \n",
    "y_future_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5843906 , -0.36296496, -0.4808569 , -0.5399871 , -0.8982251 ,\n",
       "        -0.9459039 , -0.35014212]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_future_pred, y_future_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "260px",
    "width": "258px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "205px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
