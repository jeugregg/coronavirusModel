{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time Series for COVID: Publish for app\n",
    "\n",
    "This notebook use multistep time serie model  (predicting number of cases future next days).\n",
    "\n",
    "It converts Tensorflow model into TensorFlow Lite to be able to use it in a Lambda fonction on AWS.\n",
    "\n",
    "After that, the lite model is tested and publish on AWS\n",
    "\n",
    "Finally, the lambda function is tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model in TFlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT TO DO manually:**\n",
    "- **Update TRAIN_SPLIT in my_helpers.model module**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data useful lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# helper lib\n",
    "import shutil\n",
    "import os, stat\n",
    "import re\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "# read json from http\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "# read csv from http\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# model lib\n",
    "import tensorflow as tf\n",
    "\n",
    "# from project\n",
    "from my_helpers.model import prepare_to_lambda, retrieve_from_lambda\n",
    "from my_helpers.model import prepare_to_lambda_future\n",
    "from my_helpers.model import create_list_past_hist, predict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SPLIT = 223\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_SAVE_DATA = \".\"\n",
    "PATH_DF_POS_FR = PATH_TO_SAVE_DATA + '/' + 'df_pos_fr.csv'\n",
    "PATH_DF_TEST_FR = PATH_TO_SAVE_DATA + '/' + 'df_test_fr.csv'\n",
    "PATH_JSON_METEO_FR = PATH_TO_SAVE_DATA + '/' + 'data_meteo_fr.json'\n",
    "PATH_DF_FEAT_FR = PATH_TO_SAVE_DATA + '/' + 'df_feat_fr.csv' \n",
    "PATH_GEO_DEP_FR = PATH_TO_SAVE_DATA + '/sources/geofrance/' + 'departments.csv'\n",
    "PATH_MDL_SINGLE_STEP = PATH_TO_SAVE_DATA + '/' + \"mdl_single_step_pos_fr\"\n",
    "PATH_MDL_MULTI_STEP = PATH_TO_SAVE_DATA + '/' + \"mdl_multi_step_pos_fr\"\n",
    "PATH_MDL_MULTI_TFLITE = PATH_TO_SAVE_DATA + '/' + \\\n",
    "    'serverless/tensorflow_lite_on_aws_lambda'\n",
    "PATH_MDL_MULTI_TFLITE_FILE = PATH_MDL_MULTI_TFLITE + '/' + \\\n",
    "    \"converted_model.tflite\"\n",
    "PATH_SERVERLESS = PATH_MDL_MULTI_TFLITE + '/' + 'serverless.yml'\n",
    "\n",
    "date_format = \"%Y-%m-%d\"\n",
    "\n",
    "#NB_POS_DATE_MIN_DF_FEAT = 140734 # on 13/05/2020\n",
    "NB_POS_DATE_MIN_DF_FEAT = 140227 # on 12/05/2020\n",
    "\n",
    "URL_PREDICT = 'https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev/infer'\n",
    "\n",
    "# model \n",
    "PAST_HISTORY = 14 # days used to predict next values in future\n",
    "FUTURE_TARGET = 7 # nb predict days later\n",
    "STEP = 1\n",
    "\n",
    "# plot\n",
    "NB_DAY_PLOT = FUTURE_TARGET*9\n",
    "\n",
    "# train split\n",
    "from my_helpers.model import TRAIN_SPLIT\n",
    "print(f\"TRAIN_SPLIT = {TRAIN_SPLIT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file before update\n",
    "def clean_file(path_file_name):\n",
    "    '''\n",
    "    Clean file already traited : rename file with date\n",
    "    '''\n",
    "    try:\n",
    "        d = datetime.datetime.now()\n",
    "        str_date = '_' + d.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "       \n",
    "        res_re = re.search('\\.\\w+$', path_file_name)\n",
    "        \n",
    "        path_file_name_saved = \\\n",
    "            path_file_name[0:res_re.start()] + str_date + res_re.group(0)\n",
    "         \n",
    "        shutil.move(path_file_name, path_file_name_saved) \n",
    "        print('File {} moved!'.format(path_file_name_saved))\n",
    "    except:\n",
    "        print('File {} does not exist!'.format(path_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_min</th>\n",
       "      <th>date</th>\n",
       "      <th>T_max</th>\n",
       "      <th>H_min</th>\n",
       "      <th>H_max</th>\n",
       "      <th>extrap</th>\n",
       "      <th>pos</th>\n",
       "      <th>age_pos</th>\n",
       "      <th>test</th>\n",
       "      <th>age_test</th>\n",
       "      <th>day_num</th>\n",
       "      <th>nb_cases</th>\n",
       "      <th>sum_cases</th>\n",
       "      <th>Rt</th>\n",
       "      <th>rate_pos</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>284.926667</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>290.505000</td>\n",
       "      <td>64.661017</td>\n",
       "      <td>88.135593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>881</td>\n",
       "      <td>61.023837</td>\n",
       "      <td>39034</td>\n",
       "      <td>55.429856</td>\n",
       "      <td>3</td>\n",
       "      <td>141108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.257007</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>285.050000</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>290.963333</td>\n",
       "      <td>59.406780</td>\n",
       "      <td>84.847458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>979</td>\n",
       "      <td>60.426966</td>\n",
       "      <td>41971</td>\n",
       "      <td>54.826499</td>\n",
       "      <td>4</td>\n",
       "      <td>142087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.332563</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>285.308333</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>291.920000</td>\n",
       "      <td>57.372881</td>\n",
       "      <td>82.966102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021</td>\n",
       "      <td>60.042116</td>\n",
       "      <td>47665</td>\n",
       "      <td>54.380069</td>\n",
       "      <td>5</td>\n",
       "      <td>143108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.142033</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-16</th>\n",
       "      <td>284.956667</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>293.500000</td>\n",
       "      <td>53.741379</td>\n",
       "      <td>86.534483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291</td>\n",
       "      <td>60.158076</td>\n",
       "      <td>16523</td>\n",
       "      <td>54.488471</td>\n",
       "      <td>6</td>\n",
       "      <td>143399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.761181</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-17</th>\n",
       "      <td>285.598333</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>294.446667</td>\n",
       "      <td>49.879310</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139</td>\n",
       "      <td>61.568345</td>\n",
       "      <td>6603</td>\n",
       "      <td>58.292443</td>\n",
       "      <td>0</td>\n",
       "      <td>143538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.105104</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>279.726271</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>285.392373</td>\n",
       "      <td>69.610169</td>\n",
       "      <td>92.050847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16015</td>\n",
       "      <td>48.586263</td>\n",
       "      <td>332662</td>\n",
       "      <td>47.453568</td>\n",
       "      <td>4</td>\n",
       "      <td>2589192</td>\n",
       "      <td>192170.0</td>\n",
       "      <td>1.148683</td>\n",
       "      <td>4.814196</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>279.578333</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>283.950000</td>\n",
       "      <td>71.100000</td>\n",
       "      <td>92.683333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1562</td>\n",
       "      <td>55.415493</td>\n",
       "      <td>32334</td>\n",
       "      <td>51.218346</td>\n",
       "      <td>5</td>\n",
       "      <td>2590754</td>\n",
       "      <td>176281.0</td>\n",
       "      <td>1.023533</td>\n",
       "      <td>4.830828</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>279.173333</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>283.438333</td>\n",
       "      <td>72.066667</td>\n",
       "      <td>89.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13727</td>\n",
       "      <td>46.572886</td>\n",
       "      <td>226475</td>\n",
       "      <td>48.801766</td>\n",
       "      <td>6</td>\n",
       "      <td>2604481</td>\n",
       "      <td>179385.0</td>\n",
       "      <td>1.017504</td>\n",
       "      <td>6.061155</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03</th>\n",
       "      <td>279.226271</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>283.090678</td>\n",
       "      <td>69.203390</td>\n",
       "      <td>90.542373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2876</td>\n",
       "      <td>51.449930</td>\n",
       "      <td>45631</td>\n",
       "      <td>50.162587</td>\n",
       "      <td>0</td>\n",
       "      <td>2607357</td>\n",
       "      <td>178636.0</td>\n",
       "      <td>1.002610</td>\n",
       "      <td>6.302733</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>279.273333</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>283.083333</td>\n",
       "      <td>72.933333</td>\n",
       "      <td>91.516667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28648</td>\n",
       "      <td>48.073792</td>\n",
       "      <td>421912</td>\n",
       "      <td>50.712843</td>\n",
       "      <td>1</td>\n",
       "      <td>2636005</td>\n",
       "      <td>186114.0</td>\n",
       "      <td>1.018619</td>\n",
       "      <td>6.790042</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 T_min        date       T_max      H_min      H_max  extrap  \\\n",
       "date                                                                           \n",
       "2020-05-13  284.926667  2020-05-13  290.505000  64.661017  88.135593     0.0   \n",
       "2020-05-14  285.050000  2020-05-14  290.963333  59.406780  84.847458     0.0   \n",
       "2020-05-15  285.308333  2020-05-15  291.920000  57.372881  82.966102     0.0   \n",
       "2020-05-16  284.956667  2020-05-16  293.500000  53.741379  86.534483     0.0   \n",
       "2020-05-17  285.598333  2020-05-17  294.446667  49.879310  85.500000     0.0   \n",
       "...                ...         ...         ...        ...        ...     ...   \n",
       "2020-12-31  279.726271  2020-12-31  285.392373  69.610169  92.050847     0.0   \n",
       "2021-01-01  279.578333  2021-01-01  283.950000  71.100000  92.683333     0.0   \n",
       "2021-01-02  279.173333  2021-01-02  283.438333  72.066667  89.916667     0.0   \n",
       "2021-01-03  279.226271  2021-01-03  283.090678  69.203390  90.542373     0.0   \n",
       "2021-01-04  279.273333  2021-01-04  283.083333  72.933333  91.516667     0.0   \n",
       "\n",
       "              pos    age_pos    test   age_test  day_num  nb_cases  sum_cases  \\\n",
       "date                                                                            \n",
       "2020-05-13    881  61.023837   39034  55.429856        3    141108        NaN   \n",
       "2020-05-14    979  60.426966   41971  54.826499        4    142087        NaN   \n",
       "2020-05-15   1021  60.042116   47665  54.380069        5    143108        NaN   \n",
       "2020-05-16    291  60.158076   16523  54.488471        6    143399        NaN   \n",
       "2020-05-17    139  61.568345    6603  58.292443        0    143538        NaN   \n",
       "...           ...        ...     ...        ...      ...       ...        ...   \n",
       "2020-12-31  16015  48.586263  332662  47.453568        4   2589192   192170.0   \n",
       "2021-01-01   1562  55.415493   32334  51.218346        5   2590754   176281.0   \n",
       "2021-01-02  13727  46.572886  226475  48.801766        6   2604481   179385.0   \n",
       "2021-01-03   2876  51.449930   45631  50.162587        0   2607357   178636.0   \n",
       "2021-01-04  28648  48.073792  421912  50.712843        1   2636005   186114.0   \n",
       "\n",
       "                  Rt  rate_pos  train  \n",
       "date                                   \n",
       "2020-05-13       NaN  2.257007   True  \n",
       "2020-05-14       NaN  2.332563   True  \n",
       "2020-05-15       NaN  2.142033   True  \n",
       "2020-05-16       NaN  1.761181   True  \n",
       "2020-05-17       NaN  2.105104   True  \n",
       "...              ...       ...    ...  \n",
       "2020-12-31  1.148683  4.814196  False  \n",
       "2021-01-01  1.023533  4.830828  False  \n",
       "2021-01-02  1.017504  6.061155  False  \n",
       "2021-01-03  1.002610  6.302733  False  \n",
       "2021-01-04  1.018619  6.790042  False  \n",
       "\n",
       "[237 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_fr = pd.read_csv(PATH_DF_FEAT_FR)\n",
    "df_feat_fr.index = df_feat_fr[\"date\"]\n",
    "df_feat_fr[\"train\"] = [True if I <= TRAIN_SPLIT else False \\\n",
    "                       for I in range(df_feat_fr.shape[0])]\n",
    "df_feat_fr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_min</th>\n",
       "      <th>T_max</th>\n",
       "      <th>H_min</th>\n",
       "      <th>H_max</th>\n",
       "      <th>pos</th>\n",
       "      <th>test</th>\n",
       "      <th>day_num</th>\n",
       "      <th>age_pos</th>\n",
       "      <th>age_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>284.926667</td>\n",
       "      <td>290.505000</td>\n",
       "      <td>64.661017</td>\n",
       "      <td>88.135593</td>\n",
       "      <td>881</td>\n",
       "      <td>39034</td>\n",
       "      <td>3</td>\n",
       "      <td>61.023837</td>\n",
       "      <td>55.429856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>285.050000</td>\n",
       "      <td>290.963333</td>\n",
       "      <td>59.406780</td>\n",
       "      <td>84.847458</td>\n",
       "      <td>979</td>\n",
       "      <td>41971</td>\n",
       "      <td>4</td>\n",
       "      <td>60.426966</td>\n",
       "      <td>54.826499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>285.308333</td>\n",
       "      <td>291.920000</td>\n",
       "      <td>57.372881</td>\n",
       "      <td>82.966102</td>\n",
       "      <td>1021</td>\n",
       "      <td>47665</td>\n",
       "      <td>5</td>\n",
       "      <td>60.042116</td>\n",
       "      <td>54.380069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-16</th>\n",
       "      <td>284.956667</td>\n",
       "      <td>293.500000</td>\n",
       "      <td>53.741379</td>\n",
       "      <td>86.534483</td>\n",
       "      <td>291</td>\n",
       "      <td>16523</td>\n",
       "      <td>6</td>\n",
       "      <td>60.158076</td>\n",
       "      <td>54.488471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-17</th>\n",
       "      <td>285.598333</td>\n",
       "      <td>294.446667</td>\n",
       "      <td>49.879310</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>139</td>\n",
       "      <td>6603</td>\n",
       "      <td>0</td>\n",
       "      <td>61.568345</td>\n",
       "      <td>58.292443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>279.726271</td>\n",
       "      <td>285.392373</td>\n",
       "      <td>69.610169</td>\n",
       "      <td>92.050847</td>\n",
       "      <td>16015</td>\n",
       "      <td>332662</td>\n",
       "      <td>4</td>\n",
       "      <td>48.586263</td>\n",
       "      <td>47.453568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>279.578333</td>\n",
       "      <td>283.950000</td>\n",
       "      <td>71.100000</td>\n",
       "      <td>92.683333</td>\n",
       "      <td>1562</td>\n",
       "      <td>32334</td>\n",
       "      <td>5</td>\n",
       "      <td>55.415493</td>\n",
       "      <td>51.218346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>279.173333</td>\n",
       "      <td>283.438333</td>\n",
       "      <td>72.066667</td>\n",
       "      <td>89.916667</td>\n",
       "      <td>13727</td>\n",
       "      <td>226475</td>\n",
       "      <td>6</td>\n",
       "      <td>46.572886</td>\n",
       "      <td>48.801766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03</th>\n",
       "      <td>279.226271</td>\n",
       "      <td>283.090678</td>\n",
       "      <td>69.203390</td>\n",
       "      <td>90.542373</td>\n",
       "      <td>2876</td>\n",
       "      <td>45631</td>\n",
       "      <td>0</td>\n",
       "      <td>51.449930</td>\n",
       "      <td>50.162587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>279.273333</td>\n",
       "      <td>283.083333</td>\n",
       "      <td>72.933333</td>\n",
       "      <td>91.516667</td>\n",
       "      <td>28648</td>\n",
       "      <td>421912</td>\n",
       "      <td>1</td>\n",
       "      <td>48.073792</td>\n",
       "      <td>50.712843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 T_min       T_max      H_min      H_max    pos    test  \\\n",
       "date                                                                      \n",
       "2020-05-13  284.926667  290.505000  64.661017  88.135593    881   39034   \n",
       "2020-05-14  285.050000  290.963333  59.406780  84.847458    979   41971   \n",
       "2020-05-15  285.308333  291.920000  57.372881  82.966102   1021   47665   \n",
       "2020-05-16  284.956667  293.500000  53.741379  86.534483    291   16523   \n",
       "2020-05-17  285.598333  294.446667  49.879310  85.500000    139    6603   \n",
       "...                ...         ...        ...        ...    ...     ...   \n",
       "2020-12-31  279.726271  285.392373  69.610169  92.050847  16015  332662   \n",
       "2021-01-01  279.578333  283.950000  71.100000  92.683333   1562   32334   \n",
       "2021-01-02  279.173333  283.438333  72.066667  89.916667  13727  226475   \n",
       "2021-01-03  279.226271  283.090678  69.203390  90.542373   2876   45631   \n",
       "2021-01-04  279.273333  283.083333  72.933333  91.516667  28648  421912   \n",
       "\n",
       "            day_num    age_pos   age_test  \n",
       "date                                       \n",
       "2020-05-13        3  61.023837  55.429856  \n",
       "2020-05-14        4  60.426966  54.826499  \n",
       "2020-05-15        5  60.042116  54.380069  \n",
       "2020-05-16        6  60.158076  54.488471  \n",
       "2020-05-17        0  61.568345  58.292443  \n",
       "...             ...        ...        ...  \n",
       "2020-12-31        4  48.586263  47.453568  \n",
       "2021-01-01        5  55.415493  51.218346  \n",
       "2021-01-02        6  46.572886  48.801766  \n",
       "2021-01-03        0  51.449930  50.162587  \n",
       "2021-01-04        1  48.073792  50.712843  \n",
       "\n",
       "[237 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_feat_fr.copy().filter(items=['T_min', 'T_max', 'H_min',\n",
    "                                           'H_max', 'pos', 'test', 'day_num',\n",
    "                                          'age_pos', 'age_test'])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = features.values\n",
    "data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\n",
    "data_std = dataset[:TRAIN_SPLIT].std(axis=0)\n",
    "dataset = (dataset-data_mean)/data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAST_HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x6412a60d0> and <tensorflow.python.keras.layers.core.Dropout object at 0x6403b1d50>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x6412e5610> and <tensorflow.python.keras.layers.core.Dense object at 0x6412efb90>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x6412e5610> and <tensorflow.python.keras.layers.core.Dropout object at 0x6403b1d50>).\n",
      "CPU times: user 2.09 s, sys: 135 ms, total: 2.22 s\n",
      "Wall time: 2.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reload best model\n",
    "multi_step_model = tf.keras.models.load_model(PATH_MDL_MULTI_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_step_model.inputs[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/coronavirusModel/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /anaconda3/envs/coronavirusModel/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./keras_lstm/assets\n"
     ]
    }
   ],
   "source": [
    "run_model = tf.function(lambda x: multi_step_model(x))\n",
    "# This is important, let's fix the input size.\n",
    "INPUT_SIZE = dataset.shape[1]\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([1, PAST_HISTORY, INPUT_SIZE],\n",
    "                  multi_step_model.inputs[0].dtype))\n",
    "\n",
    "# model directory.\n",
    "MODEL_DIR = PATH_TO_SAVE_DATA + \"/\" + \"keras_lstm\"\n",
    "multi_step_model.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "\n",
    "'''converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "converter.allow_custom_ops=True'''\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./serverless/tensorflow_lite_on_aws_lambda/converted_model_20210108_18_33_23.tflite moved!\n"
     ]
    }
   ],
   "source": [
    "clean_file(PATH_MDL_MULTI_TFLITE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6104"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(PATH_MDL_MULTI_TFLITE_FILE, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test converted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with TF model (not-converted one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160 - 174]\n",
      "[167 - 181]\n",
      "[174 - 188]\n",
      "[181 - 195]\n",
      "[188 - 202]\n",
      "[195 - 209]\n",
      "[202 - 216]\n",
      "[209 - 223]\n",
      "[216 - 230]\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[48774.977 , 48387.04  , 40821.426 , 27992.297 , 12843.852 ,\n",
       "        10868.523 , 34764.176 , 33760.992 , 33141.227 , 27341.578 ,\n",
       "        18373.746 ,  7751.032 ,  6830.9785, 23531.566 , 19770.203 ,\n",
       "        18980.756 , 15548.844 , 10960.39  ,  5768.2373,  5715.255 ,\n",
       "        14484.893 , 12793.738 , 12350.097 , 10456.0205,  8089.126 ,\n",
       "         5889.612 ,  6011.135 , 10196.099 , 12056.082 , 11511.448 ,\n",
       "         9788.3545,  7339.3965,  5025.651 ,  5832.9087, 10988.544 ,\n",
       "        13247.568 , 12426.34  , 10832.238 ,  8438.341 ,  5974.1606,\n",
       "         6879.1694, 12358.41  , 16208.102 , 15215.77  , 12103.836 ,\n",
       "         8854.375 ,  6047.71  ,  7148.1304, 13890.699 , 20261.703 ,\n",
       "        19739.703 , 13066.605 ,  6835.974 ,   922.2119,  3882.7031,\n",
       "        17998.76  , 21422.441 , 20446.512 , 19690.766 , 15778.641 ,\n",
       "        11032.605 , 12902.533 , 23091.342 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSORFLOW MODEL :\n",
    "# prepare list of past histories\n",
    "list_x = create_list_past_hist(dataset)\n",
    "# predict\n",
    "y_multi_pred = predict_list(list_x, multi_step_model)\n",
    "# convert in positive cases\n",
    "y_pos_pred = (y_multi_pred * data_std[4]) + data_mean[4] \n",
    "y_pos_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data : very last days\n",
    "x_for_future = np.array([dataset[-PAST_HISTORY:,:]]) \n",
    "# predict next days\n",
    "y_future_pred = multi_step_model.predict(x_for_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with TFlite & Compare "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# CONVERTED LITE MODEL\n",
    "# load \n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "\n",
    "# Run the model with TensorFlow Lite\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# check if same results \n",
    "for x_multi in list_x:\n",
    "    # predict with tensorflow model\n",
    "    expected = multi_step_model.predict(x_multi)\n",
    "    # predict with TFlite model\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], \n",
    "                           x_multi.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "    # Assert if the result of TFLite model is consistent with the TF model.\n",
    "    np.testing.assert_almost_equal(expected, result, decimal=3)\n",
    "    print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "    # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "    # the states.\n",
    "    # Clean up internal states.\n",
    "    interpreter.reset_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Tlite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=PATH_MDL_MULTI_TFLITE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./serverless/tensorflow_lite_on_aws_lambda/converted_model.tflite'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_MDL_MULTI_TFLITE_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict reloaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Run the model with TensorFlow Lite\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# check if same results \n",
    "for x_multi in list_x:\n",
    "    \n",
    "    expected = multi_step_model.predict(x_multi)\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0][\"index\"], \n",
    "                           x_multi.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "    # Assert if the result of TFLite model is consistent with the TF model.\n",
    "    np.testing.assert_almost_equal(expected, result, decimal=3)\n",
    "    print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "    # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "    # the states.\n",
    "    # Clean up internal states.\n",
    "    interpreter.reset_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update API lambda AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API lambda simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160 - 174]\n",
      "[167 - 181]\n",
      "[174 - 188]\n",
      "[181 - 195]\n",
      "[188 - 202]\n",
      "[195 - 209]\n",
      "[202 - 216]\n",
      "[209 - 223]\n",
      "[216 - 230]\n"
     ]
    }
   ],
   "source": [
    "json_list_list_x = prepare_to_lambda(dataset)\n",
    "# simulate input to lambda (double dumps ? why ? i don't know yet)\n",
    "json_list_list_x = json.dumps(json_list_list_x)\n",
    "# simulate lambda\n",
    "\n",
    "event = {\"body\": json_list_list_x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT : nb. arrays : 9 / arrays shape: (1, 14, 9)\n",
      "OUTPUT : nb. arrays : 9 / arrays shape in list: (1, 7)\n"
     ]
    }
   ],
   "source": [
    "# lambda code (file ./serverless/tensorflow-lite-on-aws-lambda/handler.py)\n",
    "from serverless.tensorflow_lite_on_aws_lambda.handler import predict\n",
    "context = None\n",
    "response = predict(event, context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve from lambda in App code\n",
    "# input : response\n",
    "y_multi_pred_out = retrieve_from_lambda(response)      \n",
    "y_multi_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.6288004 ,  2.602255  ,  2.084565  ,  1.2067096 ,  0.17015088,\n",
       "         0.03498564,  1.670087  ,  1.6014425 ,  1.5590339 ,  1.162183  ,\n",
       "         0.54854345, -0.1783341 , -0.24129039,  0.90147626,  0.6440986 ,\n",
       "         0.5900792 ,  0.3552447 ,  0.04127178, -0.3140103 , -0.31763572,\n",
       "         0.28244194,  0.16672178,  0.13636486,  0.0067594 , -0.15519947,\n",
       "        -0.305705  , -0.2973896 , -0.01102621,  0.11624643,  0.07897891,\n",
       "        -0.03892681, -0.206501  , -0.36482304, -0.30958503,  0.04319825,\n",
       "         0.1977759 ,  0.14158194,  0.03250274, -0.13130382, -0.29991964,\n",
       "        -0.23799282,  0.13693373,  0.40035552,  0.3324535 ,  0.11951406,\n",
       "        -0.10283599, -0.2948869 , -0.21958871,  0.24178323,  0.6777303 ,\n",
       "         0.6420115 ,  0.18539323, -0.24094854, -0.645608  , -0.44303125,\n",
       "         0.5228844 ,  0.75715584,  0.69037604,  0.6386628 ,  0.3709689 ,\n",
       "         0.04621322,  0.1741663 ,  0.8713532 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.62880039,  2.60225487,  2.08456492,  1.2067095 ,  0.17015123,\n",
       "         0.03498639,  1.67008746,  1.60144246,  1.55903399,  1.16218293,\n",
       "         0.54854339, -0.17833431, -0.24129054,  0.90147632,  0.64409864,\n",
       "         0.59007919,  0.35524473,  0.04127174, -0.3140105 , -0.31763598,\n",
       "         0.28244191,  0.16672169,  0.13636482,  0.00675946, -0.15519939,\n",
       "        -0.30570498, -0.2973896 , -0.01102633,  0.11624654,  0.07897896,\n",
       "        -0.03892688, -0.20650113, -0.36482304, -0.30958506,  0.04319834,\n",
       "         0.19777584,  0.14158192,  0.03250279, -0.13130376, -0.29991958,\n",
       "        -0.23799281,  0.13693365,  0.40035552,  0.33245349,  0.11951405,\n",
       "        -0.10283599, -0.29488692, -0.21958868,  0.24178326,  0.67773032,\n",
       "         0.64201152,  0.18539321, -0.24094854, -0.64560807, -0.44303131,\n",
       "         0.52288443,  0.75715578,  0.69037598,  0.63866282,  0.37096894,\n",
       "         0.04621326,  0.17416631,  0.87135327]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_multi_pred, y_multi_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT : nb. arrays : 1 / arrays shape: (1, 14, 9)\n",
      "OUTPUT : nb. arrays : 1 / arrays shape in list: (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data to lambda (future)\n",
    "json_list_list_x = prepare_to_lambda_future(dataset)\n",
    "\n",
    "# simulate lambda\n",
    "json_list_list_x = json.dumps(json_list_list_x) # dumps again : I dont know why\n",
    "event = {\"body\": json_list_list_x}\n",
    "context = None\n",
    "response = predict(event, context)\n",
    "y_future_pred_out = retrieve_from_lambda(response)      \n",
    "y_future_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.79977012,  0.68679988,  0.48965859,  0.1596892 , -0.21241954,\n",
       "        -0.05220608,  0.767407  ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.79977036,  0.68679994,  0.48965842,  0.15968896, -0.21241964,\n",
       "        -0.05220603,  0.7674072 ]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_future_pred, y_future_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update AWS Lambda with new model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part does:\n",
    "- Go to : ./serverless//tensorflow-lite-on-aws-lambda\n",
    "    \n",
    "- Execute : sls deploy -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#!/bin/bash\\nexport PATH=\"/usr/local/bin:$PATH\"\\ncd ./serverless/tensorflow_lite_on_aws_lambda\\nserverless deploy -v'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_exe = '#!/bin/bash\\n' + \\\n",
    "    'export PATH=\"/usr/local/bin:$PATH\"\\n' + \\\n",
    "    f'cd {PATH_MDL_MULTI_TFLITE}\\n' + \\\n",
    "    'serverless deploy -v'\n",
    "str_exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('deploy_serverless.sh', \"w\").write(str_exe)\n",
    "os.chmod('deploy_serverless.sh', stat.S_IRWXU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "export PATH=\"/usr/local/bin:$PATH\"\r\n",
      "cd ./serverless/tensorflow_lite_on_aws_lambda\r\n",
      "serverless deploy -v"
     ]
    }
   ],
   "source": [
    "!cat ./deploy_serverless.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serverless: \u001b[33mGenerated requirements from /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow_lite_on_aws_lambda/requirements.txt in /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow_lite_on_aws_lambda/.serverless/requirements.txt...\u001b[39m\n",
      "Serverless: \u001b[33mUsing static cache of requirements found at /Users/gregory/Library/Caches/serverless-python-requirements/ef4e42eb03bbad46f74fee99a3c01f994e8119e7a557f947779093ab37b248d3_slspyc ...\u001b[39m\n",
      "Serverless: \u001b[33mPackaging service...\u001b[39m\n",
      "Serverless: \u001b[33mExcluding development dependencies...\u001b[39m\n",
      "Serverless: \u001b[33mInjecting required Python packages to package...\u001b[39m\n",
      "Serverless: \u001b[33mUploading CloudFormation file to S3...\u001b[39m\n",
      "Serverless: \u001b[33mUploading artifacts...\u001b[39m\n",
      "Serverless: \u001b[33mUploading service tensorflow-lite-on-aws-lambda.zip file to S3 (18.4 MB)...\u001b[39m\n",
      "Serverless: \u001b[33mValidating template...\u001b[39m\n",
      "Serverless: \u001b[33mUpdating Stack...\u001b[39m\n",
      "Serverless: \u001b[33mChecking Stack update progress...\u001b[39m\n",
      "CloudFormation - \u001b[33mUPDATE_IN_PROGRESS\u001b[39m - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-dev\n",
      "CloudFormation - \u001b[33mUPDATE_IN_PROGRESS\u001b[39m - AWS::Lambda::Function - PredictLambdaFunction\n",
      "CloudFormation - \u001b[32mUPDATE_COMPLETE\u001b[39m - AWS::Lambda::Function - PredictLambdaFunction\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::Lambda::Version - PredictLambdaVersionf40EwbsOSQJN0xL5hJCkt9gMgWJ9BvVTFOdqMSgQs\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::Lambda::Version - PredictLambdaVersionf40EwbsOSQJN0xL5hJCkt9gMgWJ9BvVTFOdqMSgQs\n",
      "CloudFormation - \u001b[32mCREATE_COMPLETE\u001b[39m - AWS::Lambda::Version - PredictLambdaVersionf40EwbsOSQJN0xL5hJCkt9gMgWJ9BvVTFOdqMSgQs\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1610127373892\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1610127373892\n",
      "CloudFormation - \u001b[32mCREATE_COMPLETE\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1610127373892\n",
      "CloudFormation - \u001b[33mUPDATE_COMPLETE_CLEANUP_IN_PROGRESS\u001b[39m - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-dev\n",
      "CloudFormation - \u001b[33mDELETE_IN_PROGRESS\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1604052133085\n",
      "CloudFormation - DELETE_SKIPPED - AWS::Lambda::Version - PredictLambdaVersionfZPR6ihexVy5F4K7qfaWyE8U3GOaa1S33thT9MjYeo\n",
      "CloudFormation - \u001b[32mDELETE_COMPLETE\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1604052133085\n",
      "CloudFormation - \u001b[32mUPDATE_COMPLETE\u001b[39m - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-dev\n",
      "Serverless: \u001b[33mStack update finished...\u001b[39m\n",
      "\u001b[33m\u001b[4mService Information\u001b[24m\u001b[39m\n",
      "\u001b[33mservice:\u001b[39m tensorflow-lite-on-aws-lambda\n",
      "\u001b[33mstage:\u001b[39m dev\n",
      "\u001b[33mregion:\u001b[39m us-east-2\n",
      "\u001b[33mstack:\u001b[39m tensorflow-lite-on-aws-lambda-dev\n",
      "\u001b[33mresources:\u001b[39m 11\n",
      "\u001b[33mapi keys:\u001b[39m\n",
      "  None\n",
      "\u001b[33mendpoints:\u001b[39m\n",
      "  POST - https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev/infer\n",
      "\u001b[33mfunctions:\u001b[39m\n",
      "  predict: tensorflow-lite-on-aws-lambda-dev-predict\n",
      "\u001b[33mlayers:\u001b[39m\n",
      "  None\n",
      "\u001b[33m\u001b[4m\u001b[24m\u001b[39m\n",
      "\u001b[33m\u001b[4mStack Outputs\u001b[24m\u001b[39m\n",
      "\u001b[33m\u001b[4m\u001b[24m\u001b[39m\u001b[33mPredictLambdaFunctionQualifiedArn\u001b[39m: arn:aws:lambda:us-east-2:324466407431:function:tensorflow-lite-on-aws-lambda-dev-predict:12\n",
      "\u001b[33mServiceEndpoint\u001b[39m: https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev\n",
      "\u001b[33mServerlessDeploymentBucketName\u001b[39m: tensorflow-lite-on-aws-l-serverlessdeploymentbuck-1vuz80v36l59q\n",
      "\n",
      "Serverless: \u001b[33mRemoving old service artifacts from S3...\u001b[39m\n",
      "\n",
      "*******************************************************************************\n",
      "Serverless: \u001b[33mUpdate available. Run \"npm install -g serverless@^1.83.2\" to update\u001b[39m\n",
      "*******************************************************************************\n",
      "\n",
      "\n",
      "\u001b[33m\u001b[39m\n",
      "\u001b[33m   ╭───────────────────────────────────────╮\u001b[39m\n",
      "   \u001b[33m│\u001b[39m                                       \u001b[33m│\u001b[39m\n",
      "   \u001b[33m│\u001b[39m   Update available \u001b[2m1.79.0\u001b[22m\u001b[0m → \u001b[0m\u001b[32m2.17.0\u001b[39m    \u001b[33m│\u001b[39m\n",
      "   \u001b[33m│\u001b[39m   Run \u001b[36mnpm i -g serverless\u001b[39m to update   \u001b[33m│\u001b[39m\n",
      "   \u001b[33m│\u001b[39m                                       \u001b[33m│\u001b[39m\n",
      "\u001b[33m   ╰───────────────────────────────────────╯\u001b[39m\n",
      "\u001b[33m\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!./deploy_serverless.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API AWS real Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160 - 174]\n",
      "[167 - 181]\n",
      "[174 - 188]\n",
      "[181 - 195]\n",
      "[188 - 202]\n",
      "[195 - 209]\n",
      "[202 - 216]\n",
      "[209 - 223]\n",
      "[216 - 230]\n",
      "status code :  200\n",
      "[[[2.628800392150879, 2.602254867553711, 2.0845649242401123, 1.2067095041275024, 0.1701509952545166, 0.034986209124326706, 1.6700873374938965]], [[1.6014424562454224, 1.5590341091156006, 1.1621830463409424, 0.5485436320304871, -0.1783340722322464, -0.2412903606891632, 0.9014763236045837]], [[0.6440985798835754, 0.5900791883468628, 0.35524478554725647, 0.04127185791730881, -0.31401023268699646, -0.3176356554031372, 0.2824419438838959]], [[0.16672183573246002, 0.1363648921251297, 0.006759408861398697, -0.15519948303699493, -0.3057050108909607, -0.29738956689834595, -0.011026181280612946]], [[0.11624646186828613, 0.07897894084453583, -0.038926828652620316, -0.2065010815858841, -0.36482304334640503, -0.3095850646495819, 0.043198294937610626]], [[0.1977759301662445, 0.14158198237419128, 0.03250274807214737, -0.1313038021326065, -0.29991966485977173, -0.2379927933216095, 0.13693374395370483]], [[0.40035557746887207, 0.33245348930358887, 0.11951404809951782, -0.102836012840271, -0.29488691687583923, -0.21958862245082855, 0.2417832762002945]], [[0.6777303218841553, 0.6420115828514099, 0.18539327383041382, -0.24094845354557037, -0.6456080675125122, -0.4430312514305115, 0.5228844881057739]], [[0.7571558356285095, 0.6903760433197021, 0.6386628150939941, 0.37096890807151794, 0.04621322080492973, 0.17416630685329437, 0.8713533282279968]]]\n"
     ]
    }
   ],
   "source": [
    "# prepare input\n",
    "json_list_list_x = prepare_to_lambda(dataset)\n",
    "# REQUEST\n",
    "resp = requests.post(URL_PREDICT, json=json_list_list_x)\n",
    "print(\"status code : \", resp.status_code) \n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23498"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_list_list_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[2.628800392150879,\n",
       "   2.602254867553711,\n",
       "   2.0845649242401123,\n",
       "   1.2067095041275024,\n",
       "   0.1701509952545166,\n",
       "   0.034986209124326706,\n",
       "   1.6700873374938965]],\n",
       " [[1.6014424562454224,\n",
       "   1.5590341091156006,\n",
       "   1.1621830463409424,\n",
       "   0.5485436320304871,\n",
       "   -0.1783340722322464,\n",
       "   -0.2412903606891632,\n",
       "   0.9014763236045837]],\n",
       " [[0.6440985798835754,\n",
       "   0.5900791883468628,\n",
       "   0.35524478554725647,\n",
       "   0.04127185791730881,\n",
       "   -0.31401023268699646,\n",
       "   -0.3176356554031372,\n",
       "   0.2824419438838959]],\n",
       " [[0.16672183573246002,\n",
       "   0.1363648921251297,\n",
       "   0.006759408861398697,\n",
       "   -0.15519948303699493,\n",
       "   -0.3057050108909607,\n",
       "   -0.29738956689834595,\n",
       "   -0.011026181280612946]],\n",
       " [[0.11624646186828613,\n",
       "   0.07897894084453583,\n",
       "   -0.038926828652620316,\n",
       "   -0.2065010815858841,\n",
       "   -0.36482304334640503,\n",
       "   -0.3095850646495819,\n",
       "   0.043198294937610626]],\n",
       " [[0.1977759301662445,\n",
       "   0.14158198237419128,\n",
       "   0.03250274807214737,\n",
       "   -0.1313038021326065,\n",
       "   -0.29991966485977173,\n",
       "   -0.2379927933216095,\n",
       "   0.13693374395370483]],\n",
       " [[0.40035557746887207,\n",
       "   0.33245348930358887,\n",
       "   0.11951404809951782,\n",
       "   -0.102836012840271,\n",
       "   -0.29488691687583923,\n",
       "   -0.21958862245082855,\n",
       "   0.2417832762002945]],\n",
       " [[0.6777303218841553,\n",
       "   0.6420115828514099,\n",
       "   0.18539327383041382,\n",
       "   -0.24094845354557037,\n",
       "   -0.6456080675125122,\n",
       "   -0.4430312514305115,\n",
       "   0.5228844881057739]],\n",
       " [[0.7571558356285095,\n",
       "   0.6903760433197021,\n",
       "   0.6386628150939941,\n",
       "   0.37096890807151794,\n",
       "   0.04621322080492973,\n",
       "   0.17416630685329437,\n",
       "   0.8713533282279968]]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out = retrieve_from_lambda(resp)      \n",
    "y_multi_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.62880039,  2.60225487,  2.08456492,  1.2067095 ,  0.170151  ,\n",
       "         0.03498621,  1.67008734,  1.60144246,  1.55903411,  1.16218305,\n",
       "         0.54854363, -0.17833407, -0.24129036,  0.90147632,  0.64409858,\n",
       "         0.59007919,  0.35524479,  0.04127186, -0.31401023, -0.31763566,\n",
       "         0.28244194,  0.16672184,  0.13636489,  0.00675941, -0.15519948,\n",
       "        -0.30570501, -0.29738957, -0.01102618,  0.11624646,  0.07897894,\n",
       "        -0.03892683, -0.20650108, -0.36482304, -0.30958506,  0.04319829,\n",
       "         0.19777593,  0.14158198,  0.03250275, -0.1313038 , -0.29991966,\n",
       "        -0.23799279,  0.13693374,  0.40035558,  0.33245349,  0.11951405,\n",
       "        -0.10283601, -0.29488692, -0.21958862,  0.24178328,  0.67773032,\n",
       "         0.64201158,  0.18539327, -0.24094845, -0.64560807, -0.44303125,\n",
       "         0.52288449,  0.75715584,  0.69037604,  0.63866282,  0.37096891,\n",
       "         0.04621322,  0.17416631,  0.87135333]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.6288004 ,  2.602255  ,  2.084565  ,  1.2067096 ,  0.17015088,\n",
       "         0.03498564,  1.670087  ,  1.6014425 ,  1.5590339 ,  1.162183  ,\n",
       "         0.54854345, -0.1783341 , -0.24129039,  0.90147626,  0.6440986 ,\n",
       "         0.5900792 ,  0.3552447 ,  0.04127178, -0.3140103 , -0.31763572,\n",
       "         0.28244194,  0.16672178,  0.13636486,  0.0067594 , -0.15519947,\n",
       "        -0.305705  , -0.2973896 , -0.01102621,  0.11624643,  0.07897891,\n",
       "        -0.03892681, -0.206501  , -0.36482304, -0.30958503,  0.04319825,\n",
       "         0.1977759 ,  0.14158194,  0.03250274, -0.13130382, -0.29991964,\n",
       "        -0.23799282,  0.13693373,  0.40035552,  0.3324535 ,  0.11951406,\n",
       "        -0.10283599, -0.2948869 , -0.21958871,  0.24178323,  0.6777303 ,\n",
       "         0.6420115 ,  0.18539323, -0.24094854, -0.645608  , -0.44303125,\n",
       "         0.5228844 ,  0.75715584,  0.69037604,  0.6386628 ,  0.3709689 ,\n",
       "         0.04621322,  0.1741663 ,  0.8713532 ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_multi_pred, y_multi_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### future days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status code :  200\n",
      "[[[0.7997703552246094, 0.686799943447113, 0.48965853452682495, 0.15968912839889526, -0.21241939067840576, -0.05220573768019676, 0.7674073576927185]]]\n"
     ]
    }
   ],
   "source": [
    "# prepare input\n",
    "json_list_list_x = prepare_to_lambda_future(dataset)\n",
    "# REQUEST URL_PREDICT = 'https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev/infer' \n",
    "resp = requests.post(URL_PREDICT, json=json_list_list_x)\n",
    "print(\"status code : \", resp.status_code) \n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.79977036,  0.68679994,  0.48965853,  0.15968913, -0.21241939,\n",
       "        -0.05220574,  0.76740736]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred_out = retrieve_from_lambda(resp)      \n",
    "y_future_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.79977036,  0.68679994,  0.48965842,  0.15968896, -0.21241964,\n",
       "        -0.05220603,  0.7674072 ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_future_pred, y_future_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "260px",
    "width": "258px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "205px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
