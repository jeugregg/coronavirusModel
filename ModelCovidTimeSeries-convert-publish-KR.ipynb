{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model South Korea Time Series for COVID: Publish for app\n",
    "\n",
    "This notebook use multistep time serie model  (predicting number of cases future next days).\n",
    "\n",
    "It converts Tensorflow model into TensorFlow Lite to be able to use it in a Lambda fonction on AWS.\n",
    "\n",
    "After that, the lite model is tested and publish on AWS\n",
    "\n",
    "Finally, the lambda function is tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model in TFlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT TO DO manually:**\n",
    "- **Update TRAIN_SPLIT in my_helpers.model module**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data useful lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# helper lib\n",
    "import shutil\n",
    "import os, stat\n",
    "import re\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "# read json from http\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "# read csv from http\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# model lib\n",
    "import tensorflow as tf\n",
    "\n",
    "# from project\n",
    "from my_helpers.data_plots_kr import load_df_feat_kr\n",
    "from my_helpers.model import prepare_to_lambda, retrieve_from_lambda\n",
    "from my_helpers.model import prepare_to_lambda_future\n",
    "from my_helpers.model import create_list_past_hist, predict_list\n",
    "\n",
    "from my_helpers.model_kr import prepare_data_features_kr\n",
    "from my_helpers.model_kr import prepare_dataset_kr\n",
    "\n",
    "from my_helpers.utils import clean_file\n",
    "\n",
    "import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SPLIT = 326\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_SAVE_DATA = settings.PATH_TO_SAVE_DATA\n",
    "\n",
    "from my_helpers.model_kr import PATH_MDL_MULTI_STEP_KR\n",
    "from my_helpers.model_kr import PATH_MDL_MULTI_TFLITE_KR \n",
    "from my_helpers.model_kr import PATH_MDL_MULTI_TFLITE_FILE_KR\n",
    "from my_helpers.model_kr import PATH_SERVERLESS_KR\n",
    "from my_helpers.model_kr import URL_PREDICT_KR\n",
    "from my_helpers.model_kr import PAST_HISTORY # days used to predict next values in future\n",
    "from my_helpers.model_kr import FUTURE_TARGET  # predict 3 days later\n",
    "from my_helpers.model_kr import STEP \n",
    "\n",
    "from my_helpers.data_plots_kr import PATH_DF_FEAT_KR\n",
    "\n",
    "date_format = \"%Y-%m-%d\"\n",
    "\n",
    "#NB_POS_DATE_MIN_DF_FEAT = 140227 # on 12/05/2020\n",
    "\n",
    "# plot\n",
    "NB_DAY_PLOT = FUTURE_TARGET*9\n",
    "\n",
    "# train split\n",
    "from my_helpers.model_kr import TRAIN_SPLIT\n",
    "print(f\"TRAIN_SPLIT = {TRAIN_SPLIT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_cases</th>\n",
       "      <th>nb_tests</th>\n",
       "      <th>nb_deaths</th>\n",
       "      <th>date</th>\n",
       "      <th>day_num</th>\n",
       "      <th>Jeju</th>\n",
       "      <th>Gyeongnam</th>\n",
       "      <th>Gyeongbuk</th>\n",
       "      <th>Jeonnam</th>\n",
       "      <th>Jeonbuk</th>\n",
       "      <th>...</th>\n",
       "      <th>Rt_Jeonbuk</th>\n",
       "      <th>sum_Jeonnam</th>\n",
       "      <th>Rt_Jeonnam</th>\n",
       "      <th>sum_Gyeongbuk</th>\n",
       "      <th>Rt_Gyeongbuk</th>\n",
       "      <th>sum_Gyeongnam</th>\n",
       "      <th>Rt_Gyeongnam</th>\n",
       "      <th>sum_Jeju</th>\n",
       "      <th>Rt_Jeju</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-03</th>\n",
       "      <td>10062.0</td>\n",
       "      <td>424365.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>106.0</td>\n",
       "      <td>4.240000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-04</th>\n",
       "      <td>10156.0</td>\n",
       "      <td>434888.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.030769</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-05</th>\n",
       "      <td>10237.0</td>\n",
       "      <td>441662.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-06</th>\n",
       "      <td>10284.0</td>\n",
       "      <td>447509.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07</th>\n",
       "      <td>10331.0</td>\n",
       "      <td>456654.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-04</th>\n",
       "      <td>91239.0</td>\n",
       "      <td>6691811.0</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.846154</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1.760870</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.908046</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.115385</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-05</th>\n",
       "      <td>91637.0</td>\n",
       "      <td>6725304.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188679</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.265306</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.364486</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.037037</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-06</th>\n",
       "      <td>92055.0</td>\n",
       "      <td>6756772.0</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>2021-03-06</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.964912</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.176471</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.347826</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-07</th>\n",
       "      <td>92471.0</td>\n",
       "      <td>6776730.0</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.676923</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.168000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-08</th>\n",
       "      <td>92817.0</td>\n",
       "      <td>6794415.0</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.579710</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1.061538</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.458333</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            nb_cases   nb_tests  nb_deaths        date  day_num  Jeju  \\\n",
       "date                                                                    \n",
       "2020-04-03   10062.0   424365.0      174.0  2020-04-03      5.0   0.0   \n",
       "2020-04-04   10156.0   434888.0      177.0  2020-04-04      6.0   0.0   \n",
       "2020-04-05   10237.0   441662.0      183.0  2020-04-05      0.0   3.0   \n",
       "2020-04-06   10284.0   447509.0      186.0  2020-04-06      1.0   0.0   \n",
       "2020-04-07   10331.0   456654.0      192.0  2020-04-07      2.0   0.0   \n",
       "...              ...        ...        ...         ...      ...   ...   \n",
       "2021-03-04   91239.0  6691811.0     1619.0  2021-03-04      4.0   3.0   \n",
       "2021-03-05   91637.0  6725304.0     1627.0  2021-03-05      5.0   2.0   \n",
       "2021-03-06   92055.0  6756772.0     1632.0  2021-03-06      6.0   5.0   \n",
       "2021-03-07   92471.0  6776730.0     1634.0  2021-03-07      0.0   4.0   \n",
       "2021-03-08   92817.0  6794415.0     1642.0  2021-03-08      1.0   3.0   \n",
       "\n",
       "            Gyeongnam  Gyeongbuk  Jeonnam  Jeonbuk  ...  Rt_Jeonbuk  \\\n",
       "date                                                ...               \n",
       "2020-04-03        1.0        5.0      1.0      1.0  ...    5.000000   \n",
       "2020-04-04        1.0        1.0      0.0      0.0  ...    5.000000   \n",
       "2020-04-05        1.0        4.0      0.0      1.0  ...    6.000000   \n",
       "2020-04-06        2.0        2.0      0.0      0.0  ...    6.000000   \n",
       "2020-04-07        1.0        1.0      0.0      0.0  ...    6.000000   \n",
       "...               ...        ...      ...      ...  ...         ...   \n",
       "2021-03-04       10.0        7.0      1.0      6.0  ...    2.320000   \n",
       "2021-03-05        3.0        6.0      0.0      3.0  ...    2.188679   \n",
       "2021-03-06        5.0       13.0      3.0      4.0  ...    1.964912   \n",
       "2021-03-07        3.0       13.0      6.0      5.0  ...    1.676923   \n",
       "2021-03-08        1.0        3.0      6.0      4.0  ...    1.579710   \n",
       "\n",
       "            sum_Jeonnam  Rt_Jeonnam  sum_Gyeongbuk  Rt_Gyeongbuk  \\\n",
       "date                                                               \n",
       "2020-04-03         10.0         inf          106.0      4.240000   \n",
       "2020-04-04         10.0         inf           67.0      1.030769   \n",
       "2020-04-05          9.0    9.000000           60.0      0.789474   \n",
       "2020-04-06          9.0    9.000000           60.0      0.769231   \n",
       "2020-04-07          9.0    9.000000           60.0      0.759494   \n",
       "...                 ...         ...            ...           ...   \n",
       "2021-03-04         72.0    1.846154          162.0      1.760870   \n",
       "2021-03-05         62.0    1.265306          146.0      1.364486   \n",
       "2021-03-06         55.0    0.948276          140.0      1.176471   \n",
       "2021-03-07         53.0    0.854839          146.0      1.168000   \n",
       "2021-03-08         56.0    0.861538          138.0      1.061538   \n",
       "\n",
       "            sum_Gyeongnam  Rt_Gyeongnam  sum_Jeju   Rt_Jeju  train  \n",
       "date                                                                \n",
       "2020-04-03           20.0     20.000000       5.0       inf   True  \n",
       "2020-04-04           21.0     21.000000       5.0       inf   True  \n",
       "2020-04-05           21.0     10.500000       8.0       inf   True  \n",
       "2020-04-06           22.0      7.333333       8.0       inf   True  \n",
       "2020-04-07           22.0      5.500000       8.0       inf   True  \n",
       "...                   ...           ...       ...       ...    ...  \n",
       "2021-03-04           79.0      0.908046      29.0  1.115385  False  \n",
       "2021-03-05           73.0      0.811111      28.0  1.037037  False  \n",
       "2021-03-06           70.0      0.813953      31.0  1.347826  False  \n",
       "2021-03-07           66.0      0.741573      32.0  1.333333  False  \n",
       "2021-03-08           61.0      0.670330      35.0  1.458333  False  \n",
       "\n",
       "[340 rows x 88 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "df_feat_kr = load_df_feat_kr()\n",
    "# clean\n",
    "df_feat_kr = prepare_data_features_kr(df_feat_kr)\n",
    "# split train/test\n",
    "df_feat_kr[\"train\"] = [True if I <= TRAIN_SPLIT else False \\\n",
    "                       for I in range(df_feat_kr.shape[0])]\n",
    "df_feat_kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_cases</th>\n",
       "      <th>nb_tests</th>\n",
       "      <th>nb_deaths</th>\n",
       "      <th>date</th>\n",
       "      <th>day_num</th>\n",
       "      <th>Jeju</th>\n",
       "      <th>Gyeongnam</th>\n",
       "      <th>Gyeongbuk</th>\n",
       "      <th>Jeonnam</th>\n",
       "      <th>Jeonbuk</th>\n",
       "      <th>...</th>\n",
       "      <th>Rt_Jeonbuk</th>\n",
       "      <th>sum_Jeonnam</th>\n",
       "      <th>Rt_Jeonnam</th>\n",
       "      <th>sum_Gyeongbuk</th>\n",
       "      <th>Rt_Gyeongbuk</th>\n",
       "      <th>sum_Gyeongnam</th>\n",
       "      <th>Rt_Gyeongnam</th>\n",
       "      <th>sum_Jeju</th>\n",
       "      <th>Rt_Jeju</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-24</th>\n",
       "      <td>88120.0</td>\n",
       "      <td>6436000.0</td>\n",
       "      <td>1576.0</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.135135</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.058824</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.805405</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-25</th>\n",
       "      <td>88516.0</td>\n",
       "      <td>6482542.0</td>\n",
       "      <td>1581.0</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.790698</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.115385</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1.097902</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-26</th>\n",
       "      <td>88922.0</td>\n",
       "      <td>6521124.0</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1.701923</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.776786</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-27</th>\n",
       "      <td>89317.0</td>\n",
       "      <td>6558225.0</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>2021-02-27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.585366</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>179.0</td>\n",
       "      <td>2.057471</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-28</th>\n",
       "      <td>89672.0</td>\n",
       "      <td>6576114.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.377778</td>\n",
       "      <td>85.0</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2.342105</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            nb_cases   nb_tests  nb_deaths        date  day_num  Jeju  \\\n",
       "date                                                                    \n",
       "2021-02-24   88120.0  6436000.0     1576.0  2021-02-24      3.0   2.0   \n",
       "2021-02-25   88516.0  6482542.0     1581.0  2021-02-25      4.0   5.0   \n",
       "2021-02-26   88922.0  6521124.0     1585.0  2021-02-26      5.0   0.0   \n",
       "2021-02-27   89317.0  6558225.0     1595.0  2021-02-27      6.0   1.0   \n",
       "2021-02-28   89672.0  6576114.0     1603.0  2021-02-28      0.0   1.0   \n",
       "\n",
       "            Gyeongnam  Gyeongbuk  Jeonnam  Jeonbuk  ...  Rt_Jeonbuk  \\\n",
       "date                                                ...               \n",
       "2021-02-24        8.0       18.0      1.0      8.0  ...    2.135135   \n",
       "2021-02-25        2.0        9.0     11.0      5.0  ...    1.790698   \n",
       "2021-02-26        6.0       24.0      5.0     16.0  ...    2.333333   \n",
       "2021-02-27        1.0        7.0      5.0     20.0  ...    2.585366   \n",
       "2021-02-28        2.0        4.0      0.0      7.0  ...    2.377778   \n",
       "\n",
       "            sum_Jeonnam  Rt_Jeonnam  sum_Gyeongbuk  Rt_Gyeongbuk  \\\n",
       "date                                                               \n",
       "2021-02-24         70.0    2.058824          149.0      0.805405   \n",
       "2021-02-25         81.0    3.115385          157.0      1.097902   \n",
       "2021-02-26         82.0    3.280000          177.0      1.701923   \n",
       "2021-02-27         87.0    3.625000          179.0      2.057471   \n",
       "2021-02-28         85.0    3.400000          178.0      2.342105   \n",
       "\n",
       "            sum_Gyeongnam  Rt_Gyeongnam  sum_Jeju   Rt_Jeju  train  \n",
       "date                                                                \n",
       "2021-02-24           88.0      0.642336      24.0  1.142857  False  \n",
       "2021-02-25           85.0      0.691057      25.0  1.000000  False  \n",
       "2021-02-26           87.0      0.776786      21.0  0.750000  False  \n",
       "2021-02-27           84.0      0.807692      22.0  0.846154  False  \n",
       "2021-02-28           80.0      0.869565      23.0  0.920000  False  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_kr[df_feat_kr[\"train\"] == False].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.47702324 -0.07464522 -1.1302585  ... -0.49368896  0.99618756\n",
      "  -0.4174528 ]\n",
      " [-0.47382569 -0.16217883 -1.29915966 ... -0.49266611  1.49428134\n",
      "  -0.4174528 ]\n",
      " [-0.72643203 -0.50531056 -1.80400453 ... -0.73233384 -1.49428134\n",
      "  -0.4174528 ]\n",
      " ...\n",
      " [-0.56335705 -0.85894633  0.87936329 ...  0.84631511  1.49428134\n",
      "  -5.3578543 ]\n",
      " [-0.60172764 -0.93597591 -0.199792   ...  0.11049874 -1.49428134\n",
      "  -4.72127202]\n",
      " [-0.94706288 -0.61735358  0.49277246 ... -0.03481061 -0.99618756\n",
      "  -0.42098637]]\n",
      "data_mean :  [1.02061350e+01 1.95439673e+01 6.28565440e+01 1.83586912e+01\n",
      " 2.37263804e+02 1.82295245e+04 3.00000000e+00 4.43787904e+01]\n",
      "data_std :  [1.04246527e+01 9.52015313e+00 1.43476417e+01 6.30313145e+00\n",
      " 3.25978900e+02 1.56424897e+04 2.00765407e+00 5.94228918e+00]\n"
     ]
    }
   ],
   "source": [
    "dataset, data_std, data_mean = prepare_dataset_kr(df_feat_kr)\n",
    "print(dataset)\n",
    "print(\"data_mean : \", data_mean)\n",
    "print(\"data_std : \", data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAST_HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x639e3c390> and <tensorflow.python.keras.layers.core.Dropout object at 0x639eb23d0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x639eb2c50> and <tensorflow.python.keras.layers.core.Dense object at 0x639ec31d0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x639eb2c50> and <tensorflow.python.keras.layers.core.Dropout object at 0x639eb23d0>).\n",
      "CPU times: user 2.27 s, sys: 149 ms, total: 2.42 s\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reload best model\n",
    "multi_step_model = tf.keras.models.load_model(PATH_MDL_MULTI_STEP_KR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_step_model.inputs[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/coronavirusModel/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /anaconda3/envs/coronavirusModel/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/keras_lstm/assets\n"
     ]
    }
   ],
   "source": [
    "run_model = tf.function(lambda x: multi_step_model(x))\n",
    "# This is important, let's fix the input size.\n",
    "INPUT_SIZE = dataset.shape[1]\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([1, PAST_HISTORY, INPUT_SIZE],\n",
    "                  multi_step_model.inputs[0].dtype))\n",
    "\n",
    "# model directory.\n",
    "MODEL_DIR = PATH_TO_SAVE_DATA + \"/\" + \"keras_lstm\"\n",
    "multi_step_model.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "\n",
    "'''converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "converter.allow_custom_ops=True'''\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow_lite_on_aws_lambda_kr/converted_model_20210308_16_33_27.tflite moved!\n"
     ]
    }
   ],
   "source": [
    "clean_file(PATH_MDL_MULTI_TFLITE_FILE_KR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(PATH_MDL_MULTI_TFLITE_FILE_KR, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test converted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with TF model (not-converted one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263 - 277]\n",
      "[270 - 284]\n",
      "[277 - 291]\n",
      "[284 - 298]\n",
      "[291 - 305]\n",
      "[298 - 312]\n",
      "[305 - 319]\n",
      "[312 - 326]\n",
      "[319 - 333]\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[702.86414, 729.0875 , 736.69977, 688.97797, 653.7916 , 631.0095 ,\n",
       "        626.08215, 470.4515 , 481.029  , 487.1847 , 470.63177, 457.53943,\n",
       "        451.49536, 451.31912, 401.8062 , 414.47073, 419.2056 , 399.11536,\n",
       "        384.37756, 376.51666, 375.6153 , 398.42123, 416.94165, 425.10516,\n",
       "        409.0271 , 397.15097, 390.36792, 388.54022, 375.80865, 397.06296,\n",
       "        410.5708 , 401.27368, 393.4677 , 388.4569 , 385.42538, 355.71664,\n",
       "        357.49164, 356.8145 , 343.8663 , 335.03714, 332.2276 , 333.76288,\n",
       "        424.83344, 442.50467, 456.15222, 451.4508 , 446.40405, 443.33276,\n",
       "        440.14886, 357.32477, 380.7345 , 394.64774, 386.7549 , 379.08932,\n",
       "        373.8289 , 369.7801 , 382.63135, 408.12372, 427.1452 , 423.6209 ,\n",
       "        419.92017, 416.48627, 412.22656]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSORFLOW MODEL :\n",
    "# prepare list of past histories\n",
    "list_x = create_list_past_hist(dataset)\n",
    "# predict\n",
    "y_multi_pred = predict_list(list_x, multi_step_model)\n",
    "# convert in positive cases\n",
    "y_pos_pred = (y_multi_pred * data_std[4]) + data_mean[4] \n",
    "y_pos_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data : very last days\n",
    "x_for_future = np.array([dataset[-PAST_HISTORY:,:]]) \n",
    "# predict next days\n",
    "y_future_pred = multi_step_model.predict(x_for_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with TFlite & Compare "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# CONVERTED LITE MODEL\n",
    "# load \n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "\n",
    "# Run the model with TensorFlow Lite\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# check if same results \n",
    "for x_multi in list_x:\n",
    "    # predict with tensorflow model\n",
    "    expected = multi_step_model.predict(x_multi)\n",
    "    # predict with TFlite model\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], \n",
    "                           x_multi.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "    # Assert if the result of TFLite model is consistent with the TF model.\n",
    "    np.testing.assert_almost_equal(expected, result, decimal=3)\n",
    "    print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "    # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "    # the states.\n",
    "    # Clean up internal states.\n",
    "    interpreter.reset_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Tlite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=PATH_MDL_MULTI_TFLITE_FILE_KR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow_lite_on_aws_lambda_kr/converted_model.tflite'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_MDL_MULTI_TFLITE_FILE_KR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict reloaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Run the model with TensorFlow Lite\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# check if same results \n",
    "for x_multi in list_x:\n",
    "    \n",
    "    expected = multi_step_model.predict(x_multi)\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0][\"index\"], \n",
    "                           x_multi.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "    # Assert if the result of TFLite model is consistent with the TF model.\n",
    "    np.testing.assert_almost_equal(expected, result, decimal=3)\n",
    "    print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "    # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "    # the states.\n",
    "    # Clean up internal states.\n",
    "    interpreter.reset_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update API lambda AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API lambda simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263 - 277]\n",
      "[270 - 284]\n",
      "[277 - 291]\n",
      "[284 - 298]\n",
      "[291 - 305]\n",
      "[298 - 312]\n",
      "[305 - 319]\n",
      "[312 - 326]\n",
      "[319 - 333]\n"
     ]
    }
   ],
   "source": [
    "json_list_list_x = prepare_to_lambda(dataset)\n",
    "# simulate input to lambda (double dumps ? why ? i don't know yet)\n",
    "json_list_list_x = json.dumps(json_list_list_x)\n",
    "# simulate lambda\n",
    "\n",
    "event = {\"body\": json_list_list_x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT : nb. arrays : 9 / arrays shape: (1, 14, 8)\n",
      "OUTPUT : nb. arrays : 9 / arrays shape in list: (1, 7)\n"
     ]
    }
   ],
   "source": [
    "# lambda code (file ./serverless/tensorflow-lite-on-aws-lambda/handler.py)\n",
    "from serverless.tensorflow_lite_on_aws_lambda_kr.handler import predict\n",
    "context = None\n",
    "response = predict(event, context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve from lambda in App code\n",
    "# input : response\n",
    "y_multi_pred_out = retrieve_from_lambda(response)      \n",
    "y_multi_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4283142 , 1.5087593 , 1.5321113 , 1.385716  , 1.2777754 ,\n",
       "        1.207887  , 1.1927714 , 0.715346  , 0.7477943 , 0.7666781 ,\n",
       "        0.715899  , 0.67573583, 0.6571945 , 0.6566539 , 0.50476396,\n",
       "        0.5436147 , 0.55813974, 0.49650925, 0.4512984 , 0.42718363,\n",
       "        0.42441848, 0.4943799 , 0.5511947 , 0.5762378 , 0.5269154 ,\n",
       "        0.49048316, 0.46967486, 0.46406808, 0.42501172, 0.49021313,\n",
       "        0.53165096, 0.5031304 , 0.47918403, 0.46381247, 0.45451275,\n",
       "        0.36337575, 0.36882085, 0.3667437 , 0.32702264, 0.29993758,\n",
       "        0.29131883, 0.2960286 , 0.57540417, 0.62961394, 0.67148024,\n",
       "        0.6570579 , 0.64157605, 0.6321542 , 0.6223871 , 0.36830896,\n",
       "        0.44012263, 0.48280403, 0.45859134, 0.43507576, 0.4189384 ,\n",
       "        0.40651798, 0.44594154, 0.5241441 , 0.5824959 , 0.5716846 ,\n",
       "        0.56033176, 0.54979765, 0.53673035]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.42831445, 1.50875938, 1.53211153, 1.38571608, 1.27777541,\n",
       "        1.20788717, 1.19277155, 0.71534598, 0.74779433, 0.76667815,\n",
       "        0.71589893, 0.67573583, 0.65719444, 0.65665388, 0.50476408,\n",
       "        0.54361475, 0.55813986, 0.49650931, 0.45129839, 0.42718372,\n",
       "        0.42441854, 0.49437991, 0.55119479, 0.57623786, 0.52691537,\n",
       "        0.49048316, 0.46967489, 0.46406808, 0.42501178, 0.49021319,\n",
       "        0.53165096, 0.50313044, 0.47918409, 0.46381253, 0.4545128 ,\n",
       "        0.36337578, 0.36882088, 0.36674371, 0.32702273, 0.29993764,\n",
       "        0.29131889, 0.29602864, 0.57540423, 0.62961388, 0.67148024,\n",
       "        0.65705794, 0.64157605, 0.63215423, 0.62238711, 0.36830893,\n",
       "        0.44012263, 0.48280394, 0.45859128, 0.43507576, 0.41893834,\n",
       "        0.40651795, 0.44594151, 0.52414411, 0.58249593, 0.5716846 ,\n",
       "        0.56033182, 0.54979759, 0.53673035]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_multi_pred, y_multi_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT : nb. arrays : 1 / arrays shape: (1, 14, 8)\n",
      "OUTPUT : nb. arrays : 1 / arrays shape in list: (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data to lambda (future)\n",
    "json_list_list_x = prepare_to_lambda_future(dataset)\n",
    "\n",
    "# simulate lambda\n",
    "json_list_list_x = json.dumps(json_list_list_x) # dumps again : I dont know why\n",
    "event = {\"body\": json_list_list_x}\n",
    "context = None\n",
    "response = predict(event, context)\n",
    "y_future_pred_out = retrieve_from_lambda(response)      \n",
    "y_future_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40668079, 0.47320628, 0.51792705, 0.4898783 , 0.46490002,\n",
       "        0.44769371, 0.43746027]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4066808 , 0.47320625, 0.51792705, 0.4898783 , 0.46490002,\n",
       "        0.44769368, 0.43746024]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_future_pred, y_future_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update AWS Lambda with new model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part does:\n",
    "- Go to : ./serverless//tensorflow-lite-on-aws-lambda-kr\n",
    "    \n",
    "- Execute : sls deploy -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#!/bin/bash\\nexport PATH=\"/usr/local/bin:$PATH\"\\ncd /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow_lite_on_aws_lambda_kr\\nserverless deploy -v'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_exe = '#!/bin/bash\\n' + \\\n",
    "    'export PATH=\"/usr/local/bin:$PATH\"\\n' + \\\n",
    "    f'cd {PATH_MDL_MULTI_TFLITE_KR}\\n' + \\\n",
    "    'serverless deploy -v'\n",
    "str_exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('deploy_serverless_kr.sh', \"w\").write(str_exe)\n",
    "os.chmod('deploy_serverless_kr.sh', stat.S_IRWXU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "export PATH=\"/usr/local/bin:$PATH\"\r\n",
      "cd /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow_lite_on_aws_lambda_kr\r\n",
      "serverless deploy -v"
     ]
    }
   ],
   "source": [
    "!cat ./deploy_serverless_kr.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serverless: \u001b[33mGenerated requirements from /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow_lite_on_aws_lambda_kr/requirements.txt in /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow_lite_on_aws_lambda_kr/.serverless/requirements.txt...\u001b[39m\n",
      "Serverless: \u001b[33mUsing static cache of requirements found at /Users/gregory/Library/Caches/serverless-python-requirements/ef4e42eb03bbad46f74fee99a3c01f994e8119e7a557f947779093ab37b248d3_slspyc ...\u001b[39m\n",
      "Serverless: \u001b[33mPackaging service...\u001b[39m\n",
      "Serverless: \u001b[33mExcluding development dependencies...\u001b[39m\n",
      "Serverless: \u001b[33mInjecting required Python packages to package...\u001b[39m\n",
      "Serverless: \u001b[33mUploading CloudFormation file to S3...\u001b[39m\n",
      "Serverless: \u001b[33mUploading artifacts...\u001b[39m\n",
      "Serverless: \u001b[33mUploading service tensorflow-lite-on-aws-lambda-kr.zip file to S3 (19.22 MB)...\u001b[39m\n",
      "Serverless: \u001b[33mValidating template...\u001b[39m\n",
      "Serverless: \u001b[33mUpdating Stack...\u001b[39m\n",
      "Serverless: \u001b[33mChecking Stack update progress...\u001b[39m\n",
      "CloudFormation - \u001b[33mUPDATE_IN_PROGRESS\u001b[39m - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-kr-dev\n",
      "CloudFormation - \u001b[33mUPDATE_IN_PROGRESS\u001b[39m - AWS::Lambda::Function - PredictLambdaFunction\n",
      "CloudFormation - \u001b[32mUPDATE_COMPLETE\u001b[39m - AWS::Lambda::Function - PredictLambdaFunction\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::Lambda::Version - PredictLambdaVersionmXrS848aU5vVCOxHVlIUZ9ZRaWluhhAIlA7gIYCf2EE\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::Lambda::Version - PredictLambdaVersionmXrS848aU5vVCOxHVlIUZ9ZRaWluhhAIlA7gIYCf2EE\n",
      "CloudFormation - \u001b[32mCREATE_COMPLETE\u001b[39m - AWS::Lambda::Version - PredictLambdaVersionmXrS848aU5vVCOxHVlIUZ9ZRaWluhhAIlA7gIYCf2EE\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1615217613326\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1615217613326\n",
      "CloudFormation - \u001b[32mCREATE_COMPLETE\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1615217613326\n",
      "CloudFormation - \u001b[33mUPDATE_COMPLETE_CLEANUP_IN_PROGRESS\u001b[39m - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-kr-dev\n",
      "CloudFormation - \u001b[33mDELETE_IN_PROGRESS\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1615210359865\n",
      "CloudFormation - DELETE_SKIPPED - AWS::Lambda::Version - PredictLambdaVersionazJahDoTBZN7bep3aIiHEXSaqhO4zofyz5sx9O2s\n",
      "CloudFormation - \u001b[32mDELETE_COMPLETE\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1615210359865\n",
      "CloudFormation - \u001b[32mUPDATE_COMPLETE\u001b[39m - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-kr-dev\n",
      "Serverless: \u001b[33mStack update finished...\u001b[39m\n",
      "\u001b[33m\u001b[4mService Information\u001b[24m\u001b[39m\n",
      "\u001b[33mservice:\u001b[39m tensorflow-lite-on-aws-lambda-kr\n",
      "\u001b[33mstage:\u001b[39m dev\n",
      "\u001b[33mregion:\u001b[39m us-east-2\n",
      "\u001b[33mstack:\u001b[39m tensorflow-lite-on-aws-lambda-kr-dev\n",
      "\u001b[33mresources:\u001b[39m 11\n",
      "\u001b[33mapi keys:\u001b[39m\n",
      "  None\n",
      "\u001b[33mendpoints:\u001b[39m\n",
      "  POST - https://hauojq3o6f.execute-api.us-east-2.amazonaws.com/dev/infer\n",
      "\u001b[33mfunctions:\u001b[39m\n",
      "  predict: tensorflow-lite-on-aws-lambda-kr-dev-predict\n",
      "\u001b[33mlayers:\u001b[39m\n",
      "  None\n",
      "\u001b[33m\u001b[4m\u001b[24m\u001b[39m\n",
      "\u001b[33m\u001b[4mStack Outputs\u001b[24m\u001b[39m\n",
      "\u001b[33m\u001b[4m\u001b[24m\u001b[39m\u001b[33mPredictLambdaFunctionQualifiedArn\u001b[39m: arn:aws:lambda:us-east-2:324466407431:function:tensorflow-lite-on-aws-lambda-kr-dev-predict:3\n",
      "\u001b[33mServiceEndpoint\u001b[39m: https://hauojq3o6f.execute-api.us-east-2.amazonaws.com/dev\n",
      "\u001b[33mServerlessDeploymentBucketName\u001b[39m: tensorflow-lite-on-aws-l-serverlessdeploymentbuck-rj02mbrirkhj\n",
      "\n",
      "\n",
      "*******************************************************************************\n",
      "Serverless: \u001b[33mUpdate available. Run \"npm install -g serverless@^1.83.2\" to update\u001b[39m\n",
      "*******************************************************************************\n",
      "\n",
      "\n",
      "\u001b[33m\u001b[39m\n",
      "\u001b[33m   ╭───────────────────────────────────────╮\u001b[39m\n",
      "   \u001b[33m│\u001b[39m                                       \u001b[33m│\u001b[39m\n",
      "   \u001b[33m│\u001b[39m   Update available \u001b[2m1.79.0\u001b[22m\u001b[0m → \u001b[0m\u001b[32m2.28.7\u001b[39m    \u001b[33m│\u001b[39m\n",
      "   \u001b[33m│\u001b[39m   Run \u001b[36mnpm i -g serverless\u001b[39m to update   \u001b[33m│\u001b[39m\n",
      "   \u001b[33m│\u001b[39m                                       \u001b[33m│\u001b[39m\n",
      "\u001b[33m   ╰───────────────────────────────────────╯\u001b[39m\n",
      "\u001b[33m\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!./deploy_serverless_kr.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API AWS real Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263 - 277]\n",
      "[270 - 284]\n",
      "[277 - 291]\n",
      "[284 - 298]\n",
      "[291 - 305]\n",
      "[298 - 312]\n",
      "[305 - 319]\n",
      "[312 - 326]\n",
      "[319 - 333]\n",
      "status code :  200\n",
      "[[[1.428314447402954, 1.5087592601776123, 1.5321115255355835, 1.3857159614562988, 1.2777754068374634, 1.2078871726989746, 1.1927714347839355]], [[0.7153458595275879, 0.7477942109107971, 0.7666780352592468, 0.715898871421814, 0.6757358312606812, 0.6571943759918213, 0.656653881072998]], [[0.5047640204429626, 0.5436147451400757, 0.5581398010253906, 0.49650925397872925, 0.45129841566085815, 0.42718368768692017, 0.42441853880882263]], [[0.4943799078464508, 0.5511947274208069, 0.5762378573417664, 0.5269153714179993, 0.4904831647872925, 0.46967485547065735, 0.46406808495521545]], [[0.4250117838382721, 0.49021318554878235, 0.531650960445404, 0.5031304359436035, 0.479184091091156, 0.4638124704360962, 0.4545128047466278]], [[0.3633757531642914, 0.36882084608078003, 0.36674371361732483, 0.3270227015018463, 0.2999376058578491, 0.2913188338279724, 0.29602858424186707]], [[0.575404167175293, 0.6296138763427734, 0.6714802384376526, 0.6570579409599304, 0.6415760517120361, 0.6321542263031006, 0.6223871111869812]], [[0.3683089315891266, 0.4401226341724396, 0.48280400037765503, 0.4585913121700287, 0.4350757896900177, 0.41893839836120605, 0.40651798248291016]], [[0.4459415078163147, 0.5241441130638123, 0.582495927810669, 0.5716845989227295, 0.5603318214416504, 0.5497976541519165, 0.5367304086685181]]]\n"
     ]
    }
   ],
   "source": [
    "# prepare input\n",
    "json_list_list_x = prepare_to_lambda(dataset)\n",
    "# REQUEST\n",
    "resp = requests.post(URL_PREDICT_KR, json=json_list_list_x)\n",
    "print(\"status code : \", resp.status_code) \n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20683"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_list_list_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1.428314447402954,\n",
       "   1.5087592601776123,\n",
       "   1.5321115255355835,\n",
       "   1.3857159614562988,\n",
       "   1.2777754068374634,\n",
       "   1.2078871726989746,\n",
       "   1.1927714347839355]],\n",
       " [[0.7153458595275879,\n",
       "   0.7477942109107971,\n",
       "   0.7666780352592468,\n",
       "   0.715898871421814,\n",
       "   0.6757358312606812,\n",
       "   0.6571943759918213,\n",
       "   0.656653881072998]],\n",
       " [[0.5047640204429626,\n",
       "   0.5436147451400757,\n",
       "   0.5581398010253906,\n",
       "   0.49650925397872925,\n",
       "   0.45129841566085815,\n",
       "   0.42718368768692017,\n",
       "   0.42441853880882263]],\n",
       " [[0.4943799078464508,\n",
       "   0.5511947274208069,\n",
       "   0.5762378573417664,\n",
       "   0.5269153714179993,\n",
       "   0.4904831647872925,\n",
       "   0.46967485547065735,\n",
       "   0.46406808495521545]],\n",
       " [[0.4250117838382721,\n",
       "   0.49021318554878235,\n",
       "   0.531650960445404,\n",
       "   0.5031304359436035,\n",
       "   0.479184091091156,\n",
       "   0.4638124704360962,\n",
       "   0.4545128047466278]],\n",
       " [[0.3633757531642914,\n",
       "   0.36882084608078003,\n",
       "   0.36674371361732483,\n",
       "   0.3270227015018463,\n",
       "   0.2999376058578491,\n",
       "   0.2913188338279724,\n",
       "   0.29602858424186707]],\n",
       " [[0.575404167175293,\n",
       "   0.6296138763427734,\n",
       "   0.6714802384376526,\n",
       "   0.6570579409599304,\n",
       "   0.6415760517120361,\n",
       "   0.6321542263031006,\n",
       "   0.6223871111869812]],\n",
       " [[0.3683089315891266,\n",
       "   0.4401226341724396,\n",
       "   0.48280400037765503,\n",
       "   0.4585913121700287,\n",
       "   0.4350757896900177,\n",
       "   0.41893839836120605,\n",
       "   0.40651798248291016]],\n",
       " [[0.4459415078163147,\n",
       "   0.5241441130638123,\n",
       "   0.582495927810669,\n",
       "   0.5716845989227295,\n",
       "   0.5603318214416504,\n",
       "   0.5497976541519165,\n",
       "   0.5367304086685181]]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out = retrieve_from_lambda(resp)      \n",
    "y_multi_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.42831445, 1.50875926, 1.53211153, 1.38571596, 1.27777541,\n",
       "        1.20788717, 1.19277143, 0.71534586, 0.74779421, 0.76667804,\n",
       "        0.71589887, 0.67573583, 0.65719438, 0.65665388, 0.50476402,\n",
       "        0.54361475, 0.5581398 , 0.49650925, 0.45129842, 0.42718369,\n",
       "        0.42441854, 0.49437991, 0.55119473, 0.57623786, 0.52691537,\n",
       "        0.49048316, 0.46967486, 0.46406808, 0.42501178, 0.49021319,\n",
       "        0.53165096, 0.50313044, 0.47918409, 0.46381247, 0.4545128 ,\n",
       "        0.36337575, 0.36882085, 0.36674371, 0.3270227 , 0.29993761,\n",
       "        0.29131883, 0.29602858, 0.57540417, 0.62961388, 0.67148024,\n",
       "        0.65705794, 0.64157605, 0.63215423, 0.62238711, 0.36830893,\n",
       "        0.44012263, 0.482804  , 0.45859131, 0.43507579, 0.4189384 ,\n",
       "        0.40651798, 0.44594151, 0.52414411, 0.58249593, 0.5716846 ,\n",
       "        0.56033182, 0.54979765, 0.53673041]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4283142 , 1.5087593 , 1.5321113 , 1.385716  , 1.2777754 ,\n",
       "        1.207887  , 1.1927714 , 0.715346  , 0.7477943 , 0.7666781 ,\n",
       "        0.715899  , 0.67573583, 0.6571945 , 0.6566539 , 0.50476396,\n",
       "        0.5436147 , 0.55813974, 0.49650925, 0.4512984 , 0.42718363,\n",
       "        0.42441848, 0.4943799 , 0.5511947 , 0.5762378 , 0.5269154 ,\n",
       "        0.49048316, 0.46967486, 0.46406808, 0.42501172, 0.49021313,\n",
       "        0.53165096, 0.5031304 , 0.47918403, 0.46381247, 0.45451275,\n",
       "        0.36337575, 0.36882085, 0.3667437 , 0.32702264, 0.29993758,\n",
       "        0.29131883, 0.2960286 , 0.57540417, 0.62961394, 0.67148024,\n",
       "        0.6570579 , 0.64157605, 0.6321542 , 0.6223871 , 0.36830896,\n",
       "        0.44012263, 0.48280403, 0.45859134, 0.43507576, 0.4189384 ,\n",
       "        0.40651798, 0.44594154, 0.5241441 , 0.5824959 , 0.5716846 ,\n",
       "        0.56033176, 0.54979765, 0.53673035]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_multi_pred, y_multi_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### future days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status code :  200\n",
      "[[[0.40668079257011414, 0.4732062816619873, 0.5179270505905151, 0.4898782968521118, 0.46490001678466797, 0.44769370555877686, 0.4374602735042572]]]\n"
     ]
    }
   ],
   "source": [
    "# prepare input\n",
    "json_list_list_x = prepare_to_lambda_future(dataset)\n",
    "resp = requests.post(URL_PREDICT_KR, json=json_list_list_x)\n",
    "print(\"status code : \", resp.status_code) \n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40668079, 0.47320628, 0.51792705, 0.4898783 , 0.46490002,\n",
       "        0.44769371, 0.43746027]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred_out = retrieve_from_lambda(resp)      \n",
    "y_future_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4066808 , 0.47320625, 0.51792705, 0.4898783 , 0.46490002,\n",
       "        0.44769368, 0.43746024]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_future_pred, y_future_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "260px",
    "width": "258px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "205px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
